{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVRbi4F_KcDx"
      },
      "source": [
        "#FASE DE PREPARACIÓN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9yNT4zGtCxj"
      },
      "source": [
        "\n",
        "## Instalación de Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeaITHp1s8-z",
        "outputId": "164ddc31-1143-49cd-c3d7-2d6f25f8cf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando bibliotecas necesarias (streamlit, pyngrok, google-cloud-bigquery)...\n",
            "✓ Instalación de bibliotecas completada.\n",
            "--------------------------------------------------\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.49.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.37.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.38.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
            "Requirement already satisfied: streamlit-quill in /usr/local/lib/python3.12/dist-packages (0.0.3)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.12/dist-packages (from streamlit-quill) (1.49.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit>=0.63->streamlit-quill) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-quill) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-quill) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-quill) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-quill) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-quill) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-quill) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-quill) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-quill) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-quill) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-quill) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit-quill) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 1: INSTALAR BIBLIOTECAS NECESARIAS ---\n",
        "print(\"Instalando bibliotecas necesarias (streamlit, pyngrok, google-cloud-bigquery)...\")\n",
        "!pip install streamlit pyngrok google-cloud-bigquery -q\n",
        "print(\"✓ Instalación de bibliotecas completada.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "!pip install streamlit pandas google-cloud-bigquery\n",
        "!pip install streamlit-quill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6k2mthftGsT"
      },
      "source": [
        "## Configuración y Verificación de Credenciales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JsCjW_FtKlO",
        "outputId": "1a6e439e-2611-463b-9fca-49479b177b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verificando la existencia del archivo de credenciales en: /content/miespacioterapeutico-1283652e341e.json\n",
            "✅ El archivo de credenciales fue encontrado y está listo.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 2: VERIFICACIÓN DEL ARCHIVO DE CREDENCIALES ---\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "CREDENTIALS_FILE = \"/content/miespacioterapeutico-1283652e341e.json\"\n",
        "\n",
        "print(f\"Verificando la existencia del archivo de credenciales en: {CREDENTIALS_FILE}\")\n",
        "\n",
        "# Si el archivo no existe, pide al usuario que lo suba\n",
        "if not os.path.exists(CREDENTIALS_FILE):\n",
        "    print(\"\\n⚠️ Archivo de credenciales no encontrado. Por favor, sube el archivo 'miespacioterapeutico-1283652e341e.json' ahora.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Intenta renombrar el archivo si se subió con un nombre diferente\n",
        "    for fn in uploaded.keys():\n",
        "        if fn != CREDENTIALS_FILE.split('/')[-1]:\n",
        "            try:\n",
        "                os.rename(f\"/content/{fn}\", CREDENTIALS_FILE)\n",
        "                print(f\"✓ Archivo subido renombrado a: '{CREDENTIALS_FILE.split('/')[-1]}'\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ No se pudo renombrar el archivo subido: {e}\")\n",
        "        else:\n",
        "            print(f\"✓ Archivo subido: '{fn}'\")\n",
        "\n",
        "# Volver a verificar la existencia después de la subida\n",
        "if os.path.exists(CREDENTIALS_FILE):\n",
        "    print(\"✅ El archivo de credenciales fue encontrado y está listo.\")\n",
        "else:\n",
        "    print(\"❌ Error: El archivo de credenciales NO fue encontrado en la ruta especificada. La ejecución no continuará.\")\n",
        "    raise FileNotFoundError(\"Credenciales de BigQuery no encontradas.\")\n",
        "\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJHAkoSntXXe"
      },
      "source": [
        "## Configuración del Token de ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "blzwKNXvta_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4806ba19-28c1-4294-b267-7e5f5bb87ef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando token de ngrok...\n",
            "✓ Token de ngrok configurado.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 3: CONFIGURAR TOKEN DE NGROK ---\n",
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"32ErhfVTbh91cHC38eX9mb76hIv_5gYyLQ5cZJbVvHJA79mZK\" # Reemplaza con tu token real\n",
        "\n",
        "print(\"Configurando token de ngrok...\")\n",
        "try:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"✓ Token de ngrok configurado.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Error al configurar el token de ngrok: {e}\")\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk9xKzhTKo1t"
      },
      "source": [
        "#FASE IMPLEMENTACIÓN DE LA APLICACIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EfSWoQq2ogH"
      },
      "source": [
        "## Imports y Creación del Archivo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmLxzO_79P5R",
        "outputId": "3edcadcc-10df-405f-a2a9-48cfa0d33ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-18 21:18:34.578 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 1: IMPORTS Y CONFIGURACIÓN INICIAL ---\n",
        "import streamlit as st\n",
        "import uuid\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2.service_account import Credentials\n",
        "from datetime import timedelta\n",
        "\n",
        "# --- CONFIGURACIÓN DE PÁGINA ---\n",
        "st.set_page_config(\n",
        "    page_title=\"MiEspacioTerapeutico\",\n",
        "    page_icon=\"🧠\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me6sfpjP3ejA"
      },
      "source": [
        "## Configuración de BigQuery y Cliente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kWWP8Pu9UbM",
        "outputId": "92acfacf-43ae-427c-c4b7-62a46131441b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile -a app.py\n",
        "# --- PASO 2: CONFIGURACIÓN DE BIGQUERY ---\n",
        "PROJECT_ID = \"miespacioterapeutico\"\n",
        "DATASET_ID = \"Aplicacion_MiEspacioTerapeutico\"\n",
        "CREDENTIALS_FILE = \"miespacioterapeutico-1283652e341e.json\"\n",
        "\n",
        "if not os.path.exists(CREDENTIALS_FILE):\n",
        "    st.error(f\"Error: Archivo de credenciales NO encontrado: '{CREDENTIALS_FILE}'\")\n",
        "    st.stop()\n",
        "\n",
        "@st.cache_resource\n",
        "def get_bigquery_client():\n",
        "    try:\n",
        "        credentials = Credentials.from_service_account_file(CREDENTIALS_FILE)\n",
        "        return bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error de autenticación con BigQuery: {e}\")\n",
        "        return None\n",
        "\n",
        "client = get_bigquery_client()\n",
        "schemas = get_table_schemas(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU9UIp2W363Y"
      },
      "source": [
        "## Gestión del Estado de la Sesión (Session State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwepZ_eu3-M5",
        "outputId": "c15b4c03-999d-46d6-d64d-7123b56072b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile -a app.py\n",
        "# --- PASO 3: GESTIÓN DE ESTADO (SESSION STATE) ---\n",
        "def initialize_session_state():\n",
        "    '''Inicializa todas las listas y claves necesarias en el estado de la sesión.'''\n",
        "    keys_to_initialize = {\n",
        "        'current_patient_id': None, 'hijos_list': [],\n",
        "        'antecedentes_medicos_list': [], 'antecedentes_psiquiatricos_list': [],\n",
        "        'familiares_list': [], 'selected_msea_items': [], 'current_patient_diagnoses': [],\n",
        "        'tratamientos_farmacologicos_list': [], 'tratamientos_psiquiatricos_list': [],\n",
        "        'sesiones_list': [], 'agenda_list': [], 'examen_mental_redaccion': '', 'observaciones_generales': '', 'msea_categoria_sel': '', 'msea_subcat_sel': '',\n",
        "        'datos_administrativos': {}, 'motivo_de_consulta': {}, 'examen_mental': {},\n",
        "        'antecedentes_personales': {}, 'antecedentes_familiares': {},\n",
        "        'habitos_psicobiologicos': {}, 'diagnosticos': {}, 'tratamientos': {}, 'comprension_psicodinamica': {}\n",
        "    }\n",
        "    for key, value in keys_to_initialize.items():\n",
        "        if key not in st.session_state:\n",
        "            st.session_state[key] = value\n",
        "\n",
        "initialize_session_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jlo8xv44DPC"
      },
      "source": [
        "## Funciones de manejo de datos y lógica auxiliar\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FUNCIONES DE MANEJO DE DATOS Y LÓGICA AUXILIAR ---\n",
        "def safe_date_converter(value):\n",
        "    if pd.isna(value) or value is None: return None\n",
        "    if isinstance(value, datetime.datetime): return value.date()\n",
        "    if isinstance(value, datetime.date): return value\n",
        "    try: return pd.to_datetime(value).date()\n",
        "    except: return None\n",
        "\n",
        "def safe_time_converter(value):\n",
        "    if value is None or pd.isna(value): return None\n",
        "    if isinstance(value, datetime.time): return value\n",
        "    try: return pd.to_datetime(value).time()\n",
        "    except: return None\n",
        "\n",
        "def safe_decimal_converter(value, default=None):\n",
        "    if value is None or value == '':\n",
        "        return default\n",
        "    try:\n",
        "        return Decimal(str(value))\n",
        "    except InvalidOperation:\n",
        "        return default\n",
        "\n",
        "def generar_narrativa_examen(selected_items):\n",
        "    \"\"\"\n",
        "    Genera un texto narrativo coherente a partir de los ítems del examen mental,\n",
        "    agrupándolos por categoría para una mejor lectura clínica.\n",
        "    \"\"\"\n",
        "    if not selected_items:\n",
        "        return \"Paciente sin alteraciones significativas en las áreas evaluadas del examen mental.\"\n",
        "\n",
        "    texto_por_categoria = {}\n",
        "    for item in selected_items:\n",
        "        cat = item['categoria']\n",
        "        sub = item['subcategoria']\n",
        "        nota = item.get('notas', '').strip()\n",
        "\n",
        "        if cat not in texto_por_categoria:\n",
        "            texto_por_categoria[cat] = []\n",
        "\n",
        "        frase = sub\n",
        "        if nota:\n",
        "            frase += f\": {nota}\"\n",
        "        texto_por_categoria[cat].append(frase)\n",
        "\n",
        "    narrativa_final = []\n",
        "    for cat, frases in texto_por_categoria.items():\n",
        "        narrativa_final.append(f\"En el área de {cat.lower()}, se observa: {', '.join(frases)}.\")\n",
        "\n",
        "    return \" \".join(narrativa_final)\n",
        "\n",
        "def upsert_data(table_name, data_dict):\n",
        "    primary_key_map = {'sesiones': 'id_sesion', 'agenda': 'id_cita'}\n",
        "    primary_key = primary_key_map.get(table_name, 'id_paciente')\n",
        "    if not client or not data_dict.get(primary_key): return False\n",
        "\n",
        "    temp_table_id = None\n",
        "    try:\n",
        "        table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
        "        table = table_objects[table_name]\n",
        "        schema_cols = [field.name for field in table.schema]\n",
        "\n",
        "        cleaned_data = {k: v for k, v in data_dict.items() if k in schema_cols}\n",
        "\n",
        "        df = pd.DataFrame([cleaned_data])\n",
        "\n",
        "        for field in table.schema:\n",
        "            col_name = field.name\n",
        "            if col_name in df.columns:\n",
        "                if field.field_type == 'TIME':\n",
        "                    df[col_name] = df[col_name].apply(\n",
        "                        lambda t: t.strftime('%H:%M:%S') if pd.notna(t) and isinstance(t, datetime.time) else None\n",
        "                    )\n",
        "                elif field.field_type == 'DATE':\n",
        "                     df[col_name] = pd.to_datetime(df[col_name], errors='coerce').dt.date\n",
        "\n",
        "        job_config = bigquery.LoadJobConfig(schema=table.schema)\n",
        "        temp_table_id = f\"{PROJECT_ID}.{DATASET_ID}.temp_{table_name}_{generate_unique_id()}\"\n",
        "        load_job = client.load_table_from_dataframe(df, temp_table_id, job_config=job_config)\n",
        "        load_job.result()\n",
        "\n",
        "        update_cols = [f\"T.`{col}` = S.`{col}`\" for col in df.columns if col != primary_key]\n",
        "        insert_cols = [f\"`{col}`\" for col in df.columns]\n",
        "        source_cols = [f\"S.`{col}`\" for col in df.columns]\n",
        "\n",
        "        merge_sql = f\"\"\"MERGE `{table_id}` T USING `{temp_table_id}` S ON T.`{primary_key}` = S.`{primary_key}`\n",
        "                            WHEN MATCHED THEN UPDATE SET {', '.join(update_cols)}\n",
        "                            WHEN NOT MATCHED THEN INSERT ({', '.join(insert_cols)}) VALUES ({', '.join(source_cols)})\"\"\"\n",
        "\n",
        "        if not update_cols:\n",
        "            merge_sql = f\"\"\"MERGE `{table_id}` T USING `{temp_table_id}` S ON T.`{primary_key}` = S.`{primary_key}`\n",
        "                                WHEN NOT MATCHED THEN INSERT ({', '.join(insert_cols)}) VALUES ({', '.join(source_cols)})\"\"\"\n",
        "\n",
        "        client.query(merge_sql).result()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al guardar en '{table_name}': {e}\"); return False\n",
        "    finally:\n",
        "        if temp_table_id: client.delete_table(temp_table_id, not_found_ok=True)\n",
        "\n",
        "def delete_patient(patient_id):\n",
        "    if not client or not patient_id: return False\n",
        "    tables_to_delete_from = [\n",
        "        'agenda', 'sesiones', 'comprension_psicodinamica', 'tratamientos',\n",
        "        'diagnosticos', 'examen_mental', 'habitos_psicobiologicos',\n",
        "        'antecedentes_familiares', 'antecedentes_personales', 'enfermedad_actual',\n",
        "        'motivo_de_consulta', 'datos_administrativos', 'datos_identificacion',\n",
        "        'pacientes'\n",
        "    ]\n",
        "    try:\n",
        "        for table_name in tables_to_delete_from:\n",
        "            query = f\"DELETE FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` WHERE id_paciente = @patient_id\"\n",
        "            job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"patient_id\", \"STRING\", patient_id)])\n",
        "            client.query(query, job_config=job_config).result()\n",
        "        st.cache_data.clear()\n",
        "        st.success(\"Paciente y todos sus datos han sido eliminados permanentemente.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al eliminar el paciente: {e}\"); return False\n",
        "\n",
        "def delete_record(table_name, record_id, id_column):\n",
        "    if not client or not record_id: return False\n",
        "    try:\n",
        "        query = f\"DELETE FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` WHERE {id_column} = @record_id\"\n",
        "        job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"record_id\", \"STRING\", record_id)])\n",
        "        client.query(query, job_config=job_config).result()\n",
        "        st.success(f\"Registro eliminado de la tabla '{table_name}'.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al eliminar el registro: {e}\"); return False\n",
        "\n",
        "@st.cache_data(ttl=300)\n",
        "def get_patient_data_from_db(_client, _table_objects_dict, patient_id):\n",
        "    if not _client or not patient_id or not _table_objects_dict: return {}\n",
        "    data = {}\n",
        "    table_schemas = {name: [field.name for field in table.schema] for name, table in _table_objects_dict.items()}\n",
        "    tables_to_join = [\n",
        "        'datos_identificacion', 'datos_administrativos', 'motivo_de_consulta','enfermedad_actual',\n",
        "        'antecedentes_personales', 'antecedentes_familiares', 'habitos_psicobiologicos',\n",
        "        'examen_mental', 'diagnosticos', 'tratamientos', 'comprension_psicodinamica'\n",
        "    ]\n",
        "    joins, select_aliases = \"\", []\n",
        "    for table_name in tables_to_join:\n",
        "        alias = ''.join([part[0] for part in table_name.split('_')])\n",
        "        joins += f\"LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.{table_name}` AS {alias} ON p.id_paciente = {alias}.id_paciente \\n\"\n",
        "        select_aliases.append(f\"{alias}.*\")\n",
        "    main_query = f\"SELECT p.*, {', '.join(select_aliases)} FROM `{PROJECT_ID}.{DATASET_ID}.pacientes` AS p {joins} WHERE p.id_paciente = @patient_id LIMIT 1\"\n",
        "    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"patient_id\", \"STRING\", patient_id)])\n",
        "    try:\n",
        "        df_main = _client.query(main_query, job_config=job_config).to_dataframe()\n",
        "        all_tables = ['pacientes'] + tables_to_join\n",
        "        for table in all_tables: data[table] = {}\n",
        "        if not df_main.empty:\n",
        "            main_data_row = df_main.to_dict('records')[0]\n",
        "            for col, value in main_data_row.items():\n",
        "                if pd.notna(value):\n",
        "                    for tbl in all_tables:\n",
        "                        if col in table_schemas.get(tbl, []):\n",
        "                            data[tbl][col] = value\n",
        "                            break\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al cargar datos principales del paciente: {e}\"); return {}\n",
        "    for table_name in ['sesiones', 'agenda']:\n",
        "        try:\n",
        "            query = f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` WHERE id_paciente = @patient_id\"\n",
        "            job_config_many = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"patient_id\", \"STRING\", patient_id)])\n",
        "            df = _client.query(query, job_config_many).to_dataframe()\n",
        "            data[table_name] = df.to_dict('records') if not df.empty else []\n",
        "        except: data[table_name] = []\n",
        "    return data\n",
        "\n",
        "def on_select_patient(patient_id):\n",
        "    st.session_state.current_patient_id = patient_id\n",
        "    if patient_id:\n",
        "        with st.spinner(\"Cargando datos del paciente...\"):\n",
        "            data = get_patient_data_from_db(client, table_objects, patient_id)\n",
        "            for table, record in data.items():\n",
        "                if table not in ['sesiones', 'agenda']: st.session_state[table] = record or {}\n",
        "            st.session_state.hijos_list = list(st.session_state.get('datos_identificacion', {}).get('hijos', []) or [])\n",
        "            st.session_state.antecedentes_medicos_list = list(st.session_state.get('antecedentes_personales', {}).get('antecedentes_medicos', []) or [])\n",
        "            st.session_state.antecedentes_psiquiatricos_list = list(st.session_state.get('antecedentes_personales', {}).get('antecedentes_psiquiatricos', []) or [])\n",
        "            st.session_state.familiares_list = list(st.session_state.get('antecedentes_familiares', {}).get('familiares', []) or [])\n",
        "            st.session_state.selected_msea_items = list(st.session_state.get('examen_mental', {}).get('msea_items', []) or [])\n",
        "            st.session_state.current_patient_diagnoses = list(st.session_state.get('diagnosticos', {}).get('diagnosticos', []) or [])\n",
        "            st.session_state.tratamientos_farmacologicos_list = list(st.session_state.get('tratamientos', {}).get('farmacologico', []) or [])\n",
        "            st.session_state.tratamientos_psiquiatricos_list = list(st.session_state.get('tratamientos', {}).get('psiquiatrico', []) or [])\n",
        "            st.session_state.sesiones_list = data.get('sesiones', [])\n",
        "            st.session_state.agenda_list = data.get('agenda', [])\n",
        "    st.session_state.page = 'ficha'\n",
        "    st.rerun()\n",
        "\n",
        "@st.cache_data(ttl=3600)\n",
        "def load_reference_data(_client):\n",
        "    if not _client: return {}, [], [], {}, [], {}\n",
        "    try:\n",
        "        df_paises = client.query(f\"SELECT country_name, country_id FROM `{PROJECT_ID}.{DATASET_ID}.Paises`\").to_dataframe()\n",
        "        country_options = [''] + sorted(df_paises['country_name'].unique().tolist())\n",
        "        cities_by_country = {country: [''] + sorted(df_paises[df_paises['country_name'] == country]['country_id'].tolist()) for country in df_paises['country_name'].unique()}\n",
        "        df_em = client.query(f\"SELECT Categoria, `Sub- categoria` FROM `{PROJECT_ID}.{DATASET_ID}.Examen_mental`\").to_dataframe()\n",
        "        df_em.columns = ['Categoria', 'Sub_categoria']\n",
        "        msea_data = {cat: sorted(group['Sub_categoria'].tolist()) for cat, group in df_em.groupby('Categoria')}\n",
        "        msea_order = ['Aspecto','Vestimenta','Biotipo','Actitud','Nivel de conciencia','Estado de conciencia','Orientación','Atención','Memoria','Lenguaje','Afectividad','Inteligencia','Velocidad del pensamiento','Curso del pensamiento','Tipo del pensamiento','Contenido de pensamiento','Sensopercepción','Juicio de realidad','Psicomotricidad','Conciencia de enfermedad']\n",
        "        df_diag = client.query(f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.Diagnostico`\").to_dataframe()\n",
        "        diag_categories = sorted(list(set(df_diag['Categoría'].dropna())))\n",
        "        grouped_diag_data = df_diag.groupby(['Categoría', 'Subcategoría']).apply(lambda x: x.to_dict('records')).to_dict()\n",
        "        return msea_data, msea_order, diag_categories, grouped_diag_data, country_options, cities_by_country\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al cargar datos de referencia: {e}\"); return {}, [], [], {}, [], {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK1jZmvYRD1v",
        "outputId": "aede7cf4-1693-4b03-ad01-8219286c64e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-18 21:18:34.681 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
            "2025-09-18 21:18:34.687 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNG6avj84fdy"
      },
      "source": [
        "\n",
        "## Carga de datos de referencia e inicio de UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdSL7lsh4qEl",
        "outputId": "aebb8baa-1511-42c9-da1c-0fc709944cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile -a app.py\n",
        "# --- PASO 5: CARGA DE DATOS DE REFERENCIA E INICIO DE UI ---\n",
        "organized_msea_data, msea_category_order, diag_categories, grouped_diag_data, country_options, cities_by_country = load_reference_data(client)\n",
        "\n",
        "st.title(\"MiEspacioTerapeutico\")\n",
        "st.markdown(\"Una herramienta para la gestión profesional de expedientes.\")\n",
        "st.markdown(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_uv9uGw4sXA"
      },
      "source": [
        "## Interfaz de Usuario - Barra Lateral (Sidebar)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SX-aEOKjSfKr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFRIiv8D449z"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Interfaz de Usuario - Área Principal y Pestañas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# --- PASO 1: IMPORTS Y CONFIGURACIÓN INICIAL ---\n",
        "import streamlit as st\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re  # 👈 para limpiar HTML en narrativa\n",
        "import re\n",
        "import unicodedata\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2.service_account import Credentials\n",
        "from datetime import timedelta\n",
        "from streamlit_quill import st_quill\n",
        "from decimal import Decimal, InvalidOperation\n",
        "\n",
        "# --- FUNCIÓN PARA GENERAR IDs ÚNICOS ---\n",
        "def generate_unique_id():\n",
        "    \"\"\"Genera un ID único basado en timestamp y aleatoriedad, evitando el formato UUID.\"\"\"\n",
        "    timestamp = datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S%f')\n",
        "    random_part = os.urandom(4).hex()\n",
        "    return f\"{timestamp}_{random_part}\"\n",
        "\n",
        "# --- CONFIGURACIÓN DE PÁGINA ---\n",
        "st.set_page_config(\n",
        "    page_title=\"MiEspacioTerapeutico\",\n",
        "    page_icon=\"🧠\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# --- ESTILOS CSS Y CABECERA PERSONALIZADA ---\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        .main-header {\n",
        "            background-color: #ffffff;\n",
        "            padding: 0.5rem 1rem;\n",
        "            border-bottom: 1px solid #e0e0e0; font-size: 24px;\n",
        "            font-weight: 600; color: #31333F; position: fixed;\n",
        "            top: 0; left: 0; width: 100%; z-index: 1000;\n",
        "            text-align: center;\n",
        "            box-shadow: 0 2px 4px rgba(0,0,0,0.05);\n",
        "        }\n",
        "        .main > div { padding-top: 5rem; }\n",
        "        header { visibility: hidden; height: 0px; margin-top: -50px; }\n",
        "        .sidebar-title {\n",
        "            font-size: 22px;\n",
        "            font-weight: 600;\n",
        "            text-align: center;\n",
        "            margin-bottom: 1rem;\n",
        "            color: #31333F;\n",
        "        }\n",
        "        .page-title {\n",
        "            font-size: 28px;\n",
        "            font-weight: 600;\n",
        "        }\n",
        "        .patient-name-header {\n",
        "            font-size: 24px;\n",
        "            font-weight: 600;\n",
        "            color: #31333F;\n",
        "        }\n",
        "        .column-header {\n",
        "            color: #0072B2;\n",
        "            font-weight: 600;\n",
        "        }\n",
        "        [data-baseweb=\"tab-list\"] {\n",
        "            background-color: #F0F2F6;\n",
        "            border-radius: 8px;\n",
        "            padding: 4px;\n",
        "            display: flex;\n",
        "            width: 100%;\n",
        "        }\n",
        "        [data-baseweb=\"tab\"] {\n",
        "            flex-grow: 1;\n",
        "            justify-content: center;\n",
        "            color: #31333F;\n",
        "            font-weight: 600;\n",
        "            border-radius: 6px;\n",
        "        }\n",
        "        [data-baseweb=\"tab\"][aria-selected=\"true\"] {\n",
        "            color: #FFFFFF;\n",
        "            background-color: #FF4B4B;\n",
        "        }\n",
        "    </style>\n",
        "    <div class=\"main-header\">\n",
        "        MiEspacioTerapeutico\n",
        "    </div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# --- CONFIGURACIÓN DE BIGQUERY Y SCHEMAS ---\n",
        "PROJECT_ID = \"miespacioterapeutico\"\n",
        "DATASET_ID = \"Aplicacion_MiEspacioTerapeutico\"\n",
        "CREDENTIALS_FILE = \"miespacioterapeutico-1283652e341e.json\"\n",
        "\n",
        "@st.cache_resource\n",
        "def get_bigquery_client():\n",
        "    if not os.path.exists(CREDENTIALS_FILE):\n",
        "        st.error(f\"Error Crítico: No se encuentra el archivo de credenciales '{CREDENTIALS_FILE}'.\"); st.stop()\n",
        "    try:\n",
        "        credentials = Credentials.from_service_account_file(CREDENTIALS_FILE)\n",
        "        return bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error de autenticación con BigQuery: {e}\"); st.stop()\n",
        "client = get_bigquery_client()\n",
        "\n",
        "@st.cache_resource(ttl=3600)\n",
        "def get_table_schemas(_client):\n",
        "    if not _client: return {}\n",
        "    table_names = [\n",
        "        'pacientes', 'datos_identificacion', 'datos_administrativos', 'motivo_de_consulta',\n",
        "        'enfermedad_actual', 'antecedentes_personales', 'antecedentes_familiares',\n",
        "        'habitos_psicobiologicos', 'examen_mental', 'diagnosticos',\n",
        "        'tratamientos', 'comprension_psicodinamica', 'sesiones', 'agenda'\n",
        "    ]\n",
        "    schemas = {}\n",
        "    try:\n",
        "        for table in table_names:\n",
        "            table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{table}\"\n",
        "            schemas[table] = client.get_table(table_ref)\n",
        "        return schemas\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error crítico al cargar los esquemas de las tablas: {e}\"); return {}\n",
        "table_objects = get_table_schemas(client)\n",
        "\n",
        "# --- GESTIÓN DE ESTADO (SESSION STATE) ---\n",
        "def initialize_session_state():\n",
        "    defaults = {\n",
        "        'page': 'consultorio', 'welcome_seen': False, 'current_patient_id': None,\n",
        "        'loaded_patient_id': None,\n",
        "        'hijos_list': [], 'antecedentes_medicos_list': [], 'antecedentes_psiquiatricos_list': [],\n",
        "        'familiares_list': [], 'selected_msea_items': [], 'current_patient_diagnoses': [],\n",
        "        'tratamientos_farmacologicos_list': [], 'tratamientos_psiquiatricos_list': [],\n",
        "        'sesiones_list': [], 'agenda_list': []\n",
        "    }\n",
        "    for key, value in defaults.items():\n",
        "        if key not in st.session_state: st.session_state[key] = value\n",
        "initialize_session_state()\n",
        "\n",
        "# --- FUNCIONES DE MANEJO DE DATOS Y LÓGICA AUXILIAR ---\n",
        "def safe_date_converter(value):\n",
        "    if pd.isna(value) or value is None: return None\n",
        "    if isinstance(value, datetime.datetime): return value.date()\n",
        "    if isinstance(value, datetime.date): return value\n",
        "    try: return pd.to_datetime(value).date()\n",
        "    except: return None\n",
        "\n",
        "def safe_time_converter(value):\n",
        "    if value is None or pd.isna(value): return None\n",
        "    if isinstance(value, datetime.time): return value\n",
        "    try: return pd.to_datetime(value).time()\n",
        "    except: return None\n",
        "\n",
        "def safe_decimal_converter(value, default=None):\n",
        "    if value is None or value == '':\n",
        "        return default\n",
        "    try:\n",
        "        return Decimal(str(value))\n",
        "    except InvalidOperation:\n",
        "        return default\n",
        "\n",
        "def generar_narrativa_examen(selected_items):\n",
        "    if not selected_items:\n",
        "        return \"<p>Paciente sin alteraciones significativas en las áreas evaluadas del examen mental.</p>\"\n",
        "\n",
        "    texto_por_categoria = {}\n",
        "    for item in selected_items:\n",
        "        cat = item['categoria']\n",
        "        sub = item['subcategoria']\n",
        "        nota = item.get('notas', '').strip()\n",
        "\n",
        "        if cat not in texto_por_categoria:\n",
        "            texto_por_categoria[cat] = []\n",
        "\n",
        "        frase = f\"<strong>{sub}</strong>\"\n",
        "        if nota:\n",
        "            frase += f\": {nota}\"\n",
        "        texto_por_categoria[cat].append(frase)\n",
        "\n",
        "    narrativa_final = []\n",
        "    for cat, frases in texto_por_categoria.items():\n",
        "        narrativa_final.append(f\"<p>En el área de <strong>{cat.lower()}</strong>, se observa: {', '.join(frases)}.</p>\")\n",
        "\n",
        "    return \"\".join(narrativa_final)\n",
        "\n",
        "# ====== Narrativa V3 (texto plano, legible) con concordancia de género y normalización ======\n",
        "\n",
        "# --- Helpers para narrativa clínica (mejorados) ---\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def _strip_html_tags(s: str) -> str:\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = str(s)\n",
        "    s = re.sub(r\"<[^>]+>\", \"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def _remove_accents(s: str) -> str:\n",
        "    s = \"\" if s is None else str(s)\n",
        "    s = s.strip()\n",
        "    s = unicodedata.normalize(\"NFKD\", s)\n",
        "    return \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "\n",
        "def _canonize_display(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Normaliza a minúsculas sin acentos para reconocer subcategorías aunque\n",
        "    vengan con mayúsculas o acentos distintos. Devuelve la clave “canónica”.\n",
        "    \"\"\"\n",
        "    base = _remove_accents(s).lower()\n",
        "    base = re.sub(r\"\\s+\", \" \", base)\n",
        "    base = base.strip()\n",
        "\n",
        "    CANON = {\n",
        "        # Vestimenta\n",
        "        \"acorde a edad y contexto\": \"vestimenta_acorde\",\n",
        "        \"acorde a edad, no acorde a contexto\": \"vestimenta_no_contexto\",\n",
        "        \"desacorde a edad y contexto\": \"vestimenta_desacorde\",\n",
        "\n",
        "        # Biotipo\n",
        "        \"piqnico\": \"biotipo_picnico\",  # por si llega mal escrito\n",
        "        \"pícnico\": \"biotipo_picnico\",\n",
        "        \"astenico\": \"biotipo_astenico\",\n",
        "        \"asténico\": \"biotipo_astenico\",\n",
        "        \"atletico\": \"biotipo_atletico\",\n",
        "        \"atlético\": \"biotipo_atletico\",\n",
        "        \"displasico\": \"biotipo_displasico\",\n",
        "        \"displásico\": \"biotipo_displasico\",\n",
        "        \"ectomorfo (delgado, alargado, poca masa muscular)\": \"biotipo_ectomorfo\",\n",
        "        \"mesomorfo (musculoso, estructura osea fuerte)\": \"biotipo_mesomorfo\",\n",
        "        \"mesomorfo (musculoso, estructura ósea fuerte)\": \"biotipo_mesomorfo\",\n",
        "        \"endomorfo (predominio de grasa, cuerpo redondeado)\": \"biotipo_endomorfo\",\n",
        "\n",
        "        # Actitud (algunas más comunes)\n",
        "        \"colaboradora\": \"actitud_colaboradora\",\n",
        "        \"indiferente\": \"actitud_indiferente\",\n",
        "        \"hostil\": \"actitud_hostil\",\n",
        "        \"suspicaz\": \"actitud_suspicaz\",\n",
        "        \"negativa\": \"actitud_negativa\",\n",
        "        \"de rechazo\": \"actitud_rechazo\",\n",
        "        \"defensiva\": \"actitud_defensiva\",\n",
        "        \"oposicionista\": \"actitud_oposicionista\",\n",
        "        \"desafiante\": \"actitud_desafiante\",\n",
        "        \"sumisa\": \"actitud_sumisa\",\n",
        "        \"temerosa\": \"actitud_temorosa\",\n",
        "        \"retraida\": \"actitud_retraida\",\n",
        "        \"retraída\": \"actitud_retraida\",\n",
        "        \"apatica\": \"actitud_apatica\",\n",
        "        \"apática\": \"actitud_apatica\",\n",
        "        \"seductora\": \"actitud_seductora\",\n",
        "        \"dependiente\": \"actitud_dependiente\",\n",
        "        \"infantilizada\": \"actitud_infantilizada\",\n",
        "        \"desafectada\": \"actitud_desafectada\",\n",
        "        \"desconfiada\": \"actitud_desconfiada\",\n",
        "        \"ironica\": \"actitud_ironica\",\n",
        "        \"irónica\": \"actitud_ironica\",\n",
        "\n",
        "        # Nivel de conciencia\n",
        "        \"vigil\": \"nivel_vigil\",\n",
        "        \"somnoliente\": \"nivel_somnoliente\",\n",
        "        \"letargico\": \"nivel_letargico\",\n",
        "        \"letárgico\": \"nivel_letargico\",\n",
        "        \"estupor\": \"nivel_estupor\",\n",
        "        \"obnubilado\": \"nivel_obnubilado\",\n",
        "        \"coma\": \"nivel_coma\",\n",
        "\n",
        "        # Orientación\n",
        "        \"orientacion en persona\": \"ori_persona\",\n",
        "        \"orientación en persona\": \"ori_persona\",\n",
        "        \"orientacion en tiempo\": \"ori_tiempo\",\n",
        "        \"orientación en tiempo\": \"ori_tiempo\",\n",
        "        \"orientacion en espacio\": \"ori_espacio\",\n",
        "        \"orientación en espacio\": \"ori_espacio\",\n",
        "        \"orientacion en situacion\": \"ori_situacion\",\n",
        "        \"orientación en situación\": \"ori_situacion\",\n",
        "        \"orientacion en contexto social\": \"ori_contexto\",\n",
        "        \"orientación en contexto social\": \"ori_contexto\",\n",
        "\n",
        "        # Atención\n",
        "        \"euprosexico\": \"aten_euprosexico\",\n",
        "        \"euproséxico\": \"aten_euprosexico\",\n",
        "        \"hiperprosexica\": \"aten_hiperprosexica\",\n",
        "        \"paraporsexico\": \"aten_paraporsexico\",\n",
        "        \"fatigable\": \"aten_fatigable\",\n",
        "\n",
        "        # Lenguaje\n",
        "        \"eulalico\": \"len_eulalico\",\n",
        "        \"eulálico\": \"len_eulalico\",\n",
        "        \"bradilalia\": \"len_bradilalia\",\n",
        "        \"taquilalia\": \"len_taquilalia\",\n",
        "        \"mutismo\": \"len_mutismo\",\n",
        "\n",
        "        # Afectividad (solo algunas clave)\n",
        "        \"eutimico\": \"afecto_eutimico\",\n",
        "        \"eutímico\": \"afecto_eutimico\",\n",
        "        \"disforico\": \"afecto_disforico\",\n",
        "        \"disfórico\": \"afecto_disforico\",\n",
        "        \"euporico\": \"afecto_euporico\",\n",
        "        \"eupórico\": \"afecto_euporico\",\n",
        "        \"irritabilidad\": \"afecto_irritable\",\n",
        "        \"expansividad afectiva\": \"afecto_expansivo\",\n",
        "\n",
        "        # Inteligencia\n",
        "        \"impresiona normal\": \"intel_normal\",\n",
        "        \"impresiona por debajo del promedio\": \"intel_bajo\",\n",
        "        \"impresiona por encima del promedio\": \"intel_alto\",\n",
        "        \"impresiona con retraso\": \"intel_retraso\",\n",
        "\n",
        "        # Velocidad del pensamiento\n",
        "        \"eupsiquico\": \"pens_velocidad_eupsiquico\",\n",
        "        \"eupsíquico\": \"pens_velocidad_eupsiquico\",\n",
        "        \"bradipsiquico\": \"pens_velocidad_bradipsiquico\",\n",
        "        \"bradipsíquico\": \"pens_velocidad_bradipsiquico\",\n",
        "        \"taquipsiquico\": \"pens_velocidad_taquipsiquico\",\n",
        "        \"taquipsíquico\": \"pens_velocidad_taquipsiquico\",\n",
        "\n",
        "        # Curso del pensamiento\n",
        "        \"bloqueos del pensamiento\": \"pens_curso_bloqueos\",\n",
        "        \"perseveracion\": \"pens_curso_perseveracion\",\n",
        "        \"perseveración\": \"pens_curso_perseveracion\",\n",
        "        \"fuga de ideas\": \"pens_curso_fuga\",\n",
        "        \"pensamiento empobrecido\": \"pens_curso_empobrecido\",\n",
        "        \"tangencialidad\": \"pens_curso_tangencialidad\",\n",
        "        \"incoherencia / desorganizacion\": \"pens_curso_incoherencia\",\n",
        "        \"incoherencia / desorganización\": \"pens_curso_incoherencia\",\n",
        "        \"circunstancialidad\": \"pens_curso_circunstancialidad\",\n",
        "\n",
        "        # Tipo / Contenido pensamiento\n",
        "        \"ideas delirantes\": \"pens_tipo_delirantes\",\n",
        "        \"ideas obsesivas\": \"pens_tipo_obsesivas\",\n",
        "        \"normales\": \"pens_tipo_normales\",\n",
        "        \"ideas de culpa\": \"pens_contenido_culpa\",\n",
        "        \"ideas de persecucion / perjuicio\": \"pens_contenido_persecucion\",\n",
        "        \"ideas de persecución / perjuicio\": \"pens_contenido_persecucion\",\n",
        "        \"ideas de autorreproche\": \"pens_contenido_autorreproche\",\n",
        "        \"ideas de referencia\": \"pens_contenido_referencia\",\n",
        "        \"ideas hipocondriacas\": \"pens_contenido_hipocondria\",\n",
        "        \"ideas hipocondríacas\": \"pens_contenido_hipocondria\",\n",
        "        \"ideas de grandeza\": \"pens_contenido_grandeza\",\n",
        "        \"ideas de ruina o pobreza\": \"pens_contenido_ruina\",\n",
        "        \"ideas de nihilismo\": \"pens_contenido_nihilismo\",\n",
        "\n",
        "        # Psicomotricidad (clave “sin alteraciones”)\n",
        "        \"sin alteraciones\": \"psico_sin\",\n",
        "        \"agitacion psicomotora\": \"psico_agitacion\",\n",
        "        \"agitación psicomotora\": \"psico_agitacion\",\n",
        "        \"lentitud psicomotora\": \"psico_lentitud\",\n",
        "\n",
        "        # Sensopercepción (muy resumido)\n",
        "        \"alucinaciones auditivas\": \"senso_aauditivas\",\n",
        "        \"alucinaciones visuales\": \"senso_avisuales\",\n",
        "        \"ilusiones visuales\": \"senso_ilusiones_visuales\",\n",
        "        \"despersonalizacion\": \"senso_despers\",\n",
        "        \"despersonalización\": \"senso_despers\",\n",
        "        \"desrealizacion\": \"senso_desreal\",\n",
        "        \"desrealización\": \"senso_desreal\",\n",
        "\n",
        "        # Juicio de realidad\n",
        "        \"conservado\": \"juicio_conservado\",\n",
        "        \"alterado\": \"juicio_alterado\",\n",
        "\n",
        "        # Conciencia de enfermedad\n",
        "        \"ausente\": \"conciencia_ausente\",\n",
        "        \"presente\": \"conciencia_presente\",\n",
        "    }\n",
        "    return CANON.get(base, base)\n",
        "\n",
        "def _is_placeholder(note: str) -> bool:\n",
        "    if note is None:\n",
        "        return True\n",
        "    note = _strip_html_tags(note).strip()\n",
        "    return note in (\"\", \"**\")\n",
        "\n",
        "def _g_word(masc: str, fem: str, genero: str | None) -> str:\n",
        "    g = (genero or \"\").strip().lower()\n",
        "    if g == \"femenino\":\n",
        "        return fem\n",
        "    return masc  # por defecto masculino\n",
        "\n",
        "def _join_list(items):\n",
        "    items = [i for i in items if i]\n",
        "    if not items:\n",
        "        return \"\"\n",
        "    if len(items) == 1:\n",
        "        return items[0]\n",
        "    if len(items) == 2:\n",
        "        return f\"{items[0]} y {items[1]}\"\n",
        "    return \", \".join(items[:-1]) + f\" y {items[-1]}\"\n",
        "\n",
        "def generar_narrativa_examen_v3(selected_items, genero=None, edad=None) -> str:\n",
        "    \"\"\"\n",
        "    Genera texto clínico fluido, con género/edad opcional, sin HTML,\n",
        "    respetando tus categorías y notas.\n",
        "    \"\"\"\n",
        "    if not selected_items:\n",
        "        encabezado = \"\"\n",
        "        if genero or edad:\n",
        "            e = f\" de {int(edad)} años\" if isinstance(edad, (int, float)) and edad else \"\"\n",
        "            encabezado = f\"Paciente {_g_word('masculino', 'femenina', genero)}{e}\"\n",
        "            return f\"{encabezado}, sin alteraciones significativas en las áreas evaluadas del examen mental.\"\n",
        "        return \"Paciente sin alteraciones significativas en las áreas evaluadas del examen mental.\"\n",
        "\n",
        "    # Normaliza entradas\n",
        "    norm = []\n",
        "    for it in selected_items:\n",
        "        cat = _strip_html_tags(it.get(\"categoria\"))\n",
        "        sub = _canonize_display(_strip_html_tags(it.get(\"subcategoria\")))\n",
        "        nota = _strip_html_tags(it.get(\"notas\"))\n",
        "        norm.append({\"cat\": cat, \"sub\": sub, \"nota\": None if _is_placeholder(nota) else nota})\n",
        "\n",
        "    # Agrupa por categoría tal como las usas en la UI\n",
        "    por_cat = {}\n",
        "    for it in norm:\n",
        "        por_cat.setdefault(it[\"cat\"], []).append(it)\n",
        "\n",
        "    frases = []\n",
        "\n",
        "    # Encabezado\n",
        "    if genero or edad:\n",
        "        e = f\" de {int(edad)} años\" if isinstance(edad, (int, float)) and edad else \"\"\n",
        "        frases.append(f\"Paciente {_g_word('masculino', 'femenina', genero)}{e}\")\n",
        "\n",
        "    # Aspecto/Vestimenta/Biotipo/Actitud\n",
        "    # Vestimenta\n",
        "    if \"Vestimenta\" in por_cat:\n",
        "        vest = por_cat[\"Vestimenta\"]\n",
        "        vest_txt = None\n",
        "        vest_notas = []\n",
        "        for v in vest:\n",
        "            if v[\"sub\"] == \"vestimenta_acorde\":\n",
        "                vest_txt = _g_word(\"vestido acorde a la edad y al contexto\", \"vestida acorde a la edad y al contexto\", genero)\n",
        "            elif v[\"sub\"] == \"vestimenta_no_contexto\":\n",
        "                vest_txt = _g_word(\"vestido acorde a la edad, no acorde al contexto\", \"vestida acorde a la edad, no acorde al contexto\", genero)\n",
        "            elif v[\"sub\"] == \"vestimenta_desacorde\":\n",
        "                vest_txt = _g_word(\"vestido desacorde a la edad y al contexto\", \"vestida desacorde a la edad y al contexto\", genero)\n",
        "            if v[\"nota\"]:\n",
        "                vest_notas.append(v[\"nota\"])\n",
        "        if vest_txt:\n",
        "            if vest_notas:\n",
        "                vest_txt += f\": \" + \"; \".join(vest_notas)\n",
        "            frases.append(vest_txt)\n",
        "\n",
        "    # Biotipo\n",
        "    if \"Biotipo\" in por_cat:\n",
        "        biotipos_map = {\n",
        "            \"biotipo_picnico\": \"pícnico\",\n",
        "            \"biotipo_astenico\": \"asténico\",\n",
        "            \"biotipo_atletico\": \"atlético\",\n",
        "            \"biotipo_displasico\": \"displásico\",\n",
        "            \"biotipo_ectomorfo\": \"ectomorfo\",\n",
        "            \"biotipo_mesomorfo\": \"mesomorfo\",\n",
        "            \"biotipo_endomorfo\": \"endomorfo\",\n",
        "        }\n",
        "        bs = []\n",
        "        for b in por_cat[\"Biotipo\"]:\n",
        "            bs.append(biotipos_map.get(b[\"sub\"], _strip_html_tags(b[\"sub\"])))\n",
        "        bs = [b for b in bs if b]\n",
        "        if bs:\n",
        "            frases.append(\"biotipo \" + _join_list(bs))\n",
        "\n",
        "    # Actitud\n",
        "    if \"Actitud\" in por_cat:\n",
        "        acts = []\n",
        "        notas = []\n",
        "        for a in por_cat[\"Actitud\"]:\n",
        "            acts.append(_strip_html_tags(a[\"cat\"] and a[\"sub\"]).replace(\"actitud_\", \"\").replace(\"_\", \" \"))\n",
        "            if a[\"nota\"]:\n",
        "                notas.append(a[\"nota\"])\n",
        "        acts = [a for a in acts if a]\n",
        "        if acts:\n",
        "            frases.append(_join_list(acts))\n",
        "        if notas:\n",
        "            frases.append(\"; \".join(notas))\n",
        "\n",
        "    # Nivel de conciencia\n",
        "    if \"Nivel de conciencia\" in por_cat:\n",
        "        nv = por_cat[\"Nivel de conciencia\"]\n",
        "        lbl = []\n",
        "        for n in nv:\n",
        "            if n[\"sub\"] == \"nivel_vigil\":\n",
        "                lbl.append(\"vigil\")\n",
        "            else:\n",
        "                lbl.append(_strip_html_tags(n[\"sub\"]))\n",
        "        if lbl:\n",
        "            frases.append(_join_list(lbl))\n",
        "\n",
        "    # Orientación: persona/tiempo/espacio/situación/contexto\n",
        "    if \"Orientación\" in por_cat:\n",
        "        ori = por_cat[\"Orientación\"]\n",
        "        marks = set()\n",
        "        for o in ori:\n",
        "            marks.add(o[\"sub\"])\n",
        "        partes = []\n",
        "        if \"ori_persona\" in marks:\n",
        "            partes.append(\"persona\")\n",
        "        if \"ori_tiempo\" in marks:\n",
        "            partes.append(\"tiempo\")\n",
        "        if \"ori_espacio\" in marks:\n",
        "            partes.append(\"espacio\")\n",
        "        if \"ori_situacion\" in marks:\n",
        "            partes.append(\"situación\")\n",
        "        if \"ori_contexto\" in marks:\n",
        "            partes.append(\"contexto social\")\n",
        "        if partes:\n",
        "            frases.append(_g_word(\"orientado en \", \"orientada en \", genero) + _join_list(partes))\n",
        "\n",
        "    # Atención\n",
        "    if \"Atención\" in por_cat:\n",
        "        at = set(a[\"sub\"] for a in por_cat[\"Atención\"])\n",
        "        if \"aten_euprosexico\" in at:\n",
        "            frases.append(\"euproséxico\")\n",
        "        elif \"aten_hiperprosexica\" in at:\n",
        "            frases.append(\"hiperproséxico\")\n",
        "        elif \"aten_paraporsexico\" in at:\n",
        "            frases.append(\"paraprosexia\")\n",
        "        if any(a.get(\"nota\") for a in por_cat[\"Atención\"]):\n",
        "            frases.append(\"; \".join([a[\"nota\"] for a in por_cat[\"Atención\"] if a.get(\"nota\")]))\n",
        "\n",
        "    # Memoria (si la usas)\n",
        "    if \"Memoria\" in por_cat:\n",
        "        mems = [m[\"sub\"] for m in por_cat[\"Memoria\"]]\n",
        "        if mems:\n",
        "            frases.append(\"memoria \" + _join_list(mems))\n",
        "\n",
        "    # Afectividad\n",
        "    if \"Afectividad\" in por_cat:\n",
        "        af_map = {\n",
        "            \"afecto_eutimico\": \"eutímico\",\n",
        "            \"afecto_disforico\": \"disfórico\",\n",
        "            \"afecto_euporico\": \"eufórico\",\n",
        "            \"afecto_irritable\": \"irritable\",\n",
        "            \"afecto_expansivo\": \"expansivo\",\n",
        "        }\n",
        "        af = []\n",
        "        for a in por_cat[\"Afectividad\"]:\n",
        "            af.append(af_map.get(a[\"sub\"], _strip_html_tags(a[\"sub\"])))\n",
        "        af = [x for x in af if x]\n",
        "        if af:\n",
        "            frases.append(\"afecto \" + _join_list(af))\n",
        "\n",
        "    # Inteligencia\n",
        "    if \"Inteligencia\" in por_cat:\n",
        "        intel_map = {\n",
        "            \"intel_normal\": \"impresiona dentro del promedio\",\n",
        "            \"intel_bajo\": \"impresiona por debajo del promedio\",\n",
        "            \"intel_alto\": \"impresiona por encima del promedio\",\n",
        "            \"intel_retraso\": \"impresiona con retraso\",\n",
        "        }\n",
        "        iv = []\n",
        "        for i in por_cat[\"Inteligencia\"]:\n",
        "            iv.append(intel_map.get(i[\"sub\"], _strip_html_tags(i[\"sub\"])))\n",
        "        iv = [x for x in iv if x]\n",
        "        if iv:\n",
        "            frases.append(\"inteligencia \" + _join_list(iv))\n",
        "\n",
        "    # Lenguaje\n",
        "    if \"Lenguaje\" in por_cat:\n",
        "        l_map = {\n",
        "            \"len_eulalico\": \"eulálico\",\n",
        "            \"len_bradilalia\": \"bradilálico\",\n",
        "            \"len_taquilalia\": \"taquilálico\",\n",
        "            \"len_mutismo\": \"mutismo\",\n",
        "        }\n",
        "        ls = []\n",
        "        notas = []\n",
        "        for l in por_cat[\"Lenguaje\"]:\n",
        "            ls.append(l_map.get(l[\"sub\"], _strip_html_tags(l[\"sub\"])))\n",
        "            if l[\"nota\"]:\n",
        "                notas.append(l[\"nota\"])\n",
        "        ls = [x for x in ls if x]\n",
        "        if ls:\n",
        "            frases.append(\"lenguaje \" + _join_list(ls))\n",
        "        if notas:\n",
        "            frases.append(\"; \".join(notas))\n",
        "\n",
        "    # Pensamiento: velocidad, curso, tipo, contenido\n",
        "    if \"Velocidad del pensamiento\" in por_cat:\n",
        "        v_map = {\n",
        "            \"pens_velocidad_eupsiquico\": \"eupsíquico\",\n",
        "            \"pens_velocidad_bradipsiquico\": \"bradipsíquico\",\n",
        "            \"pens_velocidad_taquipsiquico\": \"taquipsíquico\",\n",
        "        }\n",
        "        vs = []\n",
        "        notas = []\n",
        "        for v in por_cat[\"Velocidad del pensamiento\"]:\n",
        "            vs.append(v_map.get(v[\"sub\"], _strip_html_tags(v[\"sub\"])))\n",
        "            if v[\"nota\"]:\n",
        "                notas.append(v[\"nota\"])\n",
        "        vs = [x for x in vs if x]\n",
        "        if vs:\n",
        "            frases.append(\"pensamiento \" + _join_list(vs))\n",
        "        if notas:\n",
        "            frases.append(\"Vb paciente: \" + \" \".join(notas))\n",
        "\n",
        "    if \"Curso del pensamiento\" in por_cat:\n",
        "        c_map = {\n",
        "            \"pens_curso_bloqueos\": \"bloqueos del pensamiento\",\n",
        "            \"pens_curso_perseveracion\": \"perseveración\",\n",
        "            \"pens_curso_fuga\": \"fuga de ideas\",\n",
        "            \"pens_curso_empobrecido\": \"pensamiento empobrecido\",\n",
        "            \"pens_curso_tangencialidad\": \"tangencialidad\",\n",
        "            \"pens_curso_incoherencia\": \"incoherencia/desorganización\",\n",
        "            \"pens_curso_circunstancialidad\": \"circunstancialidad\",\n",
        "        }\n",
        "        cs = []\n",
        "        notas = []\n",
        "        for c in por_cat[\"Curso del pensamiento\"]:\n",
        "            cs.append(c_map.get(c[\"sub\"], _strip_html_tags(c[\"sub\"])))\n",
        "            if c[\"nota\"]:\n",
        "                notas.append(c[\"nota\"])\n",
        "        cs = [x for x in cs if x]\n",
        "        if cs:\n",
        "            frases.append(\"con \" + _join_list(cs))\n",
        "        if notas:\n",
        "            # Si hay una sola y parece cita, la mantenemos\n",
        "            frases.append(\" \".join(notas))\n",
        "\n",
        "    if \"Tipo del pensamiento\" in por_cat:\n",
        "        ts = [_strip_html_tags(t[\"sub\"]) for t in por_cat[\"Tipo del pensamiento\"]]\n",
        "        ts = [x for x in ts if x]\n",
        "        if ts:\n",
        "            frases.append(\"con \" + _join_list(ts))\n",
        "\n",
        "    if \"Contenido de pensamiento\" in por_cat:\n",
        "        cont = []\n",
        "        notas = []\n",
        "        for t in por_cat[\"Contenido de pensamiento\"]:\n",
        "            cont.append(_strip_html_tags(t[\"sub\"]))\n",
        "            if t[\"nota\"]:\n",
        "                notas.append(t[\"nota\"])\n",
        "        cont = [x for x in cont if x]\n",
        "        if cont:\n",
        "            frases.append(_join_list(cont))\n",
        "        if notas:\n",
        "            frases.append(\"Vb paciente: \" + \" \".join(notas))\n",
        "\n",
        "    # Psicomotricidad\n",
        "    if \"Psicomotricidad\" in por_cat:\n",
        "        ps = []\n",
        "        notas = []\n",
        "        for p in por_cat[\"Psicomotricidad\"]:\n",
        "            if p[\"sub\"] == \"psico_sin\":\n",
        "                ps.append(\"sin alteraciones\")\n",
        "            else:\n",
        "                ps.append(_strip_html_tags(p[\"sub\"]))\n",
        "            if p[\"nota\"]:\n",
        "                notas.append(p[\"nota\"])\n",
        "        ps = [x for x in ps if x]\n",
        "        if ps:\n",
        "            frases.append(_join_list(ps))\n",
        "        if notas:\n",
        "            frases.append(\"; \".join(notas))\n",
        "\n",
        "    # Sensopercepción\n",
        "    if \"Sensopercepción\" in por_cat:\n",
        "        ss = [_strip_html_tags(s[\"sub\"]) for s in por_cat[\"Sensopercepción\"]]\n",
        "        ss = [x for x in ss if x]\n",
        "        if ss:\n",
        "            frases.append(\"sensopercepción \" + _join_list(ss))\n",
        "\n",
        "    # Juicio\n",
        "    if \"Juicio de realidad\" in por_cat:\n",
        "        j = set(t[\"sub\"] for t in por_cat[\"Juicio de realidad\"])\n",
        "        if \"juicio_conservado\" in j:\n",
        "            frases.append(\"juicio de realidad conservado\")\n",
        "        elif \"juicio_alterado\" in j:\n",
        "            frases.append(\"juicio de realidad alterado\")\n",
        "\n",
        "    # Conciencia\n",
        "    if \"Conciencia de enfermedad\" in por_cat:\n",
        "        c = set(t[\"sub\"] for t in por_cat[\"Conciencia de enfermedad\"])\n",
        "        if \"conciencia_presente\" in c:\n",
        "            frases.append(\"conciencia de enfermedad presente\")\n",
        "        elif \"conciencia_ausente\" in c:\n",
        "            frases.append(\"conciencia de enfermedad ausente\")\n",
        "\n",
        "    # Unir todo con comas y punto final. Arreglo de espacios y dobles palabras\n",
        "    texto = \", \".join([f for f in frases if f])\n",
        "    texto = re.sub(r\"\\s{2,}\", \" \", texto).strip()\n",
        "    # Arreglos de repeticiones tipo \"impresiona impresiona\"\n",
        "    texto = re.sub(r\"\\b(impresiona)\\s+\\1\\b\", r\"\\1\", texto)\n",
        "    if texto and not texto.endswith(\".\"):\n",
        "        texto += \".\"\n",
        "    return texto\n",
        "\n",
        "#--------final del bloque examen mental\n",
        "# ====== Asistente de Enfermedad Actual (helpers + diálogo) ======\n",
        "\n",
        "def generar_narrativa_ea(datos_paciente, intro, sintomas, desarrollo, citas):\n",
        "    \"\"\"\n",
        "    Ensambla la narrativa de la Enfermedad Actual a partir de las piezas proporcionadas.\n",
        "    Usa placeholders [CITA_1], [CITA_2], ... que luego se reemplazan por \"Vb.\" formateados.\n",
        "    \"\"\"\n",
        "    partes = []\n",
        "\n",
        "    # 1) Intro\n",
        "    if intro and intro.strip():\n",
        "        partes.append(intro.strip())\n",
        "\n",
        "    # 2) Síntomas\n",
        "    if sintomas and sintomas.strip():\n",
        "        if partes:\n",
        "            partes.append(\"La sintomatología principal se caracteriza por:\")\n",
        "        partes.append(sintomas.strip())\n",
        "\n",
        "    # 3) Desarrollo/estado actual\n",
        "    if desarrollo and desarrollo.strip():\n",
        "        if partes:\n",
        "            partes.append(\"En cuanto al desarrollo y estado actual:\")\n",
        "        partes.append(desarrollo.strip())\n",
        "\n",
        "    texto = \"\\n\\n\".join(partes)\n",
        "\n",
        "    # 4) Reemplazar placeholders de citas\n",
        "    if citas:\n",
        "        for i, cita in enumerate(citas):\n",
        "            placeholder = f\"[CITA_{i+1}]\"\n",
        "            fuente = (cita.get('fuente') or '').strip()\n",
        "            quien = (cita.get('quien') or '').strip()\n",
        "            texto_cita = (cita.get('texto') or '').strip()\n",
        "\n",
        "            if not texto_cita:\n",
        "                continue\n",
        "\n",
        "            if fuente in (\"Familiar\", \"Otro\") and quien:\n",
        "                cita_fmt = f'(Vb. {fuente.lower()} - {quien}: “{texto_cita}”)'\n",
        "            else:\n",
        "                fuente_lbl = fuente.lower() if fuente else \"paciente\"\n",
        "                cita_fmt = f'(Vb. {fuente_lbl}: “{texto_cita}”)'\n",
        "\n",
        "            texto = texto.replace(placeholder, cita_fmt)\n",
        "\n",
        "    return texto\n",
        "\n",
        "\n",
        "@st.dialog(\"✍️ Asistente de Redacción: Enfermedad Actual\", width=\"large\")\n",
        "def enfermedad_actual_assistant_dialog():\n",
        "    \"\"\"\n",
        "    Ventana modal para guiar la redacción de la Enfermedad Actual.\n",
        "    Consistente con el patrón del Examen Mental (vista previa + copiar + usar).\n",
        "    \"\"\"\n",
        "    # Estado del asistente\n",
        "    if 'ea_asistente_citas' not in st.session_state:\n",
        "        st.session_state.ea_asistente_citas = []\n",
        "    if 'ea_narrativa_generada' not in st.session_state:\n",
        "        st.session_state.ea_narrativa_generada = \"\"\n",
        "\n",
        "    st.caption(\"Rellena las secciones y (opcionalmente) usa [CITA_1], [CITA_2], ... donde quieras insertar verbatims.\")\n",
        "    st.divider()\n",
        "\n",
        "    # --- 1) Intro sugerida con datos de identificación ---\n",
        "    st.subheader(\"1. Inicio y desencadenante\")\n",
        "    id_data = st.session_state.get('datos_identificacion', {})\n",
        "    genero_str = \"femenina\" if (id_data.get('genero') or \"\").lower() == 'femenino' else \"masculino\"\n",
        "    edad_val = id_data.get('edad', '')\n",
        "    ciudad_nac = id_data.get('ciudad_nacimiento', '')\n",
        "    ciudad_proc = id_data.get('ciudad_procedencia', '')\n",
        "\n",
        "    sugerencia_intro = (\n",
        "        f\"Paciente {genero_str}\"\n",
        "        f\"{f' de {int(edad_val)} años' if str(edad_val).isdigit() else ''}, \"\n",
        "        f\"natural de {ciudad_nac or 'N/A'} y procedente de {ciudad_proc or 'N/A'}. \"\n",
        "        \"Consulta por...\"\n",
        "    )\n",
        "\n",
        "    st.text_area(\n",
        "        \"Redacta el párrafo introductorio (inicio del cuadro y desencadenante)\",\n",
        "        value=sugerencia_intro,\n",
        "        key=\"ea_asistente_intro\",\n",
        "        height=140\n",
        "    )\n",
        "\n",
        "    # --- 2) Sintomatología ---\n",
        "    st.subheader(\"2. Sintomatología\")\n",
        "    st.multiselect(\n",
        "        \"Categorías guía (opcional)\",\n",
        "        options=[\n",
        "            'Síntomas Afectivos', 'Síntomas Psicóticos', 'Síntomas Ansiosos',\n",
        "            'Alteraciones del Sueño', 'Alteraciones de la Conducta',\n",
        "            'Síntomas Somáticos', 'Síntomas Cognitivos'\n",
        "        ],\n",
        "        key=\"ea_asistente_cat_sintomas\"\n",
        "    )\n",
        "    st.text_area(\n",
        "        \"Describe los síntomas. Usa [CITA_1], [CITA_2], ... para insertar verbatims donde correspondan.\",\n",
        "        key=\"ea_asistente_sintomas\",\n",
        "        height=180\n",
        "    )\n",
        "\n",
        "    # --- 3) Citas / Verbatims ---\n",
        "    st.subheader(\"3. Citas textuales (verbatims)\")\n",
        "    with st.form(\"form_add_cita_ea\", clear_on_submit=True):\n",
        "        c1, c2 = st.columns(2)\n",
        "        fuente = c1.selectbox(\"Fuente\", [\"Paciente\", \"Familiar\", \"Otro\"], key=\"ea_cita_fuente\")\n",
        "        quien = c2.text_input(\"¿Quién? (Ej: hija, esposo)\", key=\"ea_cita_quien\")\n",
        "        texto_cita = st.text_area(\"Texto de la cita\", key=\"ea_cita_texto\")\n",
        "        if st.form_submit_button(\"Añadir Cita\"):\n",
        "            if (texto_cita or \"\").strip():\n",
        "                st.session_state.ea_asistente_citas.append({\n",
        "                    \"fuente\": fuente,\n",
        "                    \"quien\": quien,\n",
        "                    \"texto\": texto_cita\n",
        "                })\n",
        "                st.rerun()\n",
        "\n",
        "    if st.session_state.ea_asistente_citas:\n",
        "        st.write(\"**Citas añadidas (usa sus placeholders):**\")\n",
        "        for i, cita in enumerate(st.session_state.ea_asistente_citas):\n",
        "            placeholder = f\"[CITA_{i+1}]\"\n",
        "            quien_lbl = f\" ({cita['quien']})\" if cita.get('quien') else \"\"\n",
        "            st.info(f\"**{placeholder}** — {cita['fuente']}{quien_lbl}: “{cita['texto']}”\")\n",
        "\n",
        "    # --- 4) Desarrollo / Estado actual ---\n",
        "    st.subheader(\"4. Desarrollo y estado actual\")\n",
        "    st.text_area(\n",
        "        \"Describe la progresión del cuadro y el motivo de consulta actual.\",\n",
        "        key=\"ea_asistente_desarrollo\",\n",
        "        height=140\n",
        "    )\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # --- Generar y mostrar resultado ---\n",
        "    if st.button(\"✨ Generar narrativa\", type=\"primary\", use_container_width=True):\n",
        "        st.session_state.ea_narrativa_generada = generar_narrativa_ea(\n",
        "            datos_paciente=st.session_state.get('datos_identificacion', {}),\n",
        "            intro=st.session_state.get(\"ea_asistente_intro\", \"\"),\n",
        "            sintomas=st.session_state.get(\"ea_asistente_sintomas\", \"\"),\n",
        "            desarrollo=st.session_state.get(\"ea_asistente_desarrollo\", \"\"),\n",
        "            citas=st.session_state.get(\"ea_asistente_citas\", []),\n",
        "        )\n",
        "\n",
        "    if st.session_state.ea_narrativa_generada:\n",
        "        st.subheader(\"Vista previa (texto)\")\n",
        "        st.text(st.session_state.ea_narrativa_generada)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"**Copiar este contenido (botón copiar arriba a la derecha):**\")\n",
        "        st.code(st.session_state.ea_narrativa_generada, language=\"markdown\")\n",
        "\n",
        "        c1, c2 = st.columns(2)\n",
        "        if c1.button(\"✅ Usar en Enfermedad Actual\", use_container_width=True):\n",
        "            st.session_state.ea_temp = st.session_state.ea_narrativa_generada\n",
        "            st.session_state.ea_asistente_citas = []\n",
        "            st.session_state.ea_narrativa_generada = \"\"\n",
        "            st.rerun()\n",
        "        if c2.button(\"Cerrar\", use_container_width=True):\n",
        "            st.rerun()\n",
        "\n",
        "#---final de helper enfermedad actual------\n",
        "\n",
        "def upsert_data(table_name, data_dict):\n",
        "    primary_key_map = {'sesiones': 'id_sesion', 'agenda': 'id_cita'}\n",
        "    primary_key = primary_key_map.get(table_name, 'id_paciente')\n",
        "    if not client or not data_dict.get(primary_key): return False\n",
        "\n",
        "    temp_table_id = None\n",
        "    try:\n",
        "        table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
        "        table = table_objects[table_name]\n",
        "        schema_cols = [field.name for field in table.schema]\n",
        "\n",
        "        cleaned_data = {k: v for k, v in data_dict.items() if k in schema_cols}\n",
        "\n",
        "        df = pd.DataFrame([cleaned_data])\n",
        "\n",
        "        for field in table.schema:\n",
        "            col_name = field.name\n",
        "            if col_name in df.columns:\n",
        "                if field.field_type == 'TIME':\n",
        "                    df[col_name] = df[col_name].apply(\n",
        "                        lambda t: t.strftime('%H:%M:%S') if pd.notna(t) and isinstance(t, datetime.time) else None\n",
        "                    )\n",
        "                elif field.field_type == 'DATE':\n",
        "                     df[col_name] = pd.to_datetime(df[col_name], errors='coerce').dt.date\n",
        "\n",
        "        job_config = bigquery.LoadJobConfig(schema=table.schema)\n",
        "        temp_table_id = f\"{PROJECT_ID}.{DATASET_ID}.temp_{table_name}_{generate_unique_id()}\"\n",
        "        load_job = client.load_table_from_dataframe(df, temp_table_id, job_config=job_config)\n",
        "        load_job.result()\n",
        "\n",
        "        update_cols = [f\"T.`{col}` = S.`{col}`\" for col in df.columns if col != primary_key]\n",
        "        insert_cols = [f\"`{col}`\" for col in df.columns]\n",
        "        source_cols = [f\"S.`{col}`\" for col in df.columns]\n",
        "\n",
        "        merge_sql = f\"\"\"MERGE `{table_id}` T USING `{temp_table_id}` S ON T.`{primary_key}` = S.`{primary_key}`\n",
        "                            WHEN MATCHED THEN UPDATE SET {', '.join(update_cols)}\n",
        "                            WHEN NOT MATCHED THEN INSERT ({', '.join(insert_cols)}) VALUES ({', '.join(source_cols)})\"\"\"\n",
        "\n",
        "        if not update_cols:\n",
        "            merge_sql = f\"\"\"MERGE `{table_id}` T USING `{temp_table_id}` S ON T.`{primary_key}` = S.`{primary_key}`\n",
        "                                WHEN NOT MATCHED THEN INSERT ({', '.join(insert_cols)}) VALUES ({', '.join(source_cols)})\"\"\"\n",
        "\n",
        "        client.query(merge_sql).result()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al guardar en '{table_name}': {e}\"); return False\n",
        "    finally:\n",
        "        if temp_table_id: client.delete_table(temp_table_id, not_found_ok=True)\n",
        "\n",
        "def delete_patient(patient_id):\n",
        "    if not client or not patient_id: return False\n",
        "    tables_to_delete_from = [\n",
        "        'agenda', 'sesiones', 'comprension_psicodinamica', 'tratamientos',\n",
        "        'diagnosticos', 'examen_mental', 'habitos_psicobiologicos',\n",
        "        'antecedentes_familiares', 'antecedentes_personales', 'enfermedad_actual',\n",
        "        'motivo_de_consulta', 'datos_administrativos', 'datos_identificacion',\n",
        "        'pacientes'\n",
        "    ]\n",
        "    try:\n",
        "        for table_name in tables_to_delete_from:\n",
        "            query = f\"DELETE FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` WHERE id_paciente = @patient_id\"\n",
        "            job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"patient_id\", \"STRING\", patient_id)])\n",
        "            client.query(query, job_config=job_config).result()\n",
        "        st.cache_data.clear()\n",
        "        st.success(\"Paciente y todos sus datos han sido eliminados permanentemente.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al eliminar el paciente: {e}\"); return False\n",
        "\n",
        "def delete_record(table_name, record_id, id_column):\n",
        "    if not client or not record_id: return False\n",
        "    try:\n",
        "        query = f\"DELETE FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` WHERE {id_column} = @record_id\"\n",
        "        job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"record_id\", \"STRING\", record_id)])\n",
        "        client.query(query, job_config=job_config).result()\n",
        "        st.success(f\"Registro eliminado de la tabla '{table_name}'.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al eliminar el registro: {e}\"); return False\n",
        "\n",
        "@st.cache_data(ttl=300)\n",
        "def get_patient_data_from_db(_client, _table_objects_dict, patient_id):\n",
        "    if not _client or not patient_id or not _table_objects_dict: return {}\n",
        "    data = {}\n",
        "    table_schemas = {name: [field.name for field in table.schema] for name, table in _table_objects_dict.items()}\n",
        "    tables_to_join = [\n",
        "        'datos_identificacion', 'datos_administrativos', 'motivo_de_consulta','enfermedad_actual',\n",
        "        'antecedentes_personales', 'antecedentes_familiares', 'habitos_psicobiologicos',\n",
        "        'examen_mental', 'diagnosticos', 'tratamientos', 'comprension_psicodinamica'\n",
        "    ]\n",
        "    joins, select_aliases = \"\", []\n",
        "    for table_name in tables_to_join:\n",
        "        alias = ''.join([part[0] for part in table_name.split('_')])\n",
        "        joins += f\"LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.{table_name}` AS {alias} ON p.id_paciente = {alias}.id_paciente \\n\"\n",
        "        select_aliases.append(f\"{alias}.*\")\n",
        "    main_query = f\"SELECT p.*, {', '.join(select_aliases)} FROM `{PROJECT_ID}.{DATASET_ID}.pacientes` AS p {joins} WHERE p.id_paciente = @patient_id LIMIT 1\"\n",
        "    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"patient_id\", \"STRING\", patient_id)])\n",
        "    try:\n",
        "        df_main = _client.query(main_query, job_config=job_config).to_dataframe()\n",
        "        all_tables = ['pacientes'] + tables_to_join\n",
        "        for table in all_tables: data[table] = {}\n",
        "        if not df_main.empty:\n",
        "            main_data_row = df_main.to_dict('records')[0]\n",
        "            for col, value in main_data_row.items():\n",
        "                if isinstance(value, (list, np.ndarray)) or pd.notna(value):\n",
        "                    for tbl in all_tables:\n",
        "                        if col in table_schemas.get(tbl, []):\n",
        "                            data[tbl][col] = value\n",
        "                            break\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al cargar datos principales del paciente: {e}\"); return {}\n",
        "    for table_name in ['sesiones', 'agenda']:\n",
        "        try:\n",
        "            query = f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` WHERE id_paciente = @patient_id\"\n",
        "            job_config_many = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"patient_id\", \"STRING\", patient_id)])\n",
        "            df = _client.query(query, job_config_many).to_dataframe()\n",
        "            data[table_name] = df.to_dict('records') if not df.empty else []\n",
        "        except: data[table_name] = []\n",
        "    return data\n",
        "\n",
        "def load_data_for_current_patient():\n",
        "    patient_id = st.session_state.current_patient_id\n",
        "    with st.spinner(\"Cargando datos del paciente...\"):\n",
        "        data = get_patient_data_from_db(client, table_objects, patient_id)\n",
        "        for table, record in data.items():\n",
        "            if table not in ['sesiones', 'agenda']: st.session_state[table] = record or {}\n",
        "\n",
        "        def robust_list_loader(source_dict, key):\n",
        "            value = source_dict.get(key)\n",
        "            if isinstance(value, np.ndarray):\n",
        "                return value.tolist()\n",
        "            elif value is not None:\n",
        "                return list(value)\n",
        "            return []\n",
        "\n",
        "        st.session_state.hijos_list = robust_list_loader(st.session_state.get('datos_identificacion', {}), 'hijos')\n",
        "        st.session_state.antecedentes_medicos_list = robust_list_loader(st.session_state.get('antecedentes_personales', {}), 'antecedentes_medicos')\n",
        "        st.session_state.antecedentes_psiquiatricos_list = robust_list_loader(st.session_state.get('antecedentes_personales', {}), 'antecedentes_psiquiatricos')\n",
        "        st.session_state.familiares_list = robust_list_loader(st.session_state.get('antecedentes_familiares', {}), 'familiares')\n",
        "        st.session_state.selected_msea_items = robust_list_loader(st.session_state.get('examen_mental', {}), 'msea_items')\n",
        "        st.session_state.current_patient_diagnoses = robust_list_loader(st.session_state.get('diagnosticos', {}), 'diagnosticos')\n",
        "        st.session_state.tratamientos_farmacologicos_list = robust_list_loader(st.session_state.get('tratamientos', {}), 'farmacologico')\n",
        "        st.session_state.tratamientos_psiquiatricos_list = robust_list_loader(st.session_state.get('tratamientos', {}), 'psiquiatrico')\n",
        "\n",
        "        st.session_state.sesiones_list = data.get('sesiones', [])\n",
        "        st.session_state.agenda_list = data.get('agenda', [])\n",
        "    st.session_state.loaded_patient_id = patient_id\n",
        "\n",
        "def on_select_patient(patient_id):\n",
        "    st.session_state.current_patient_id = patient_id\n",
        "    st.session_state.page = 'ficha'\n",
        "    st.rerun()\n",
        "\n",
        "@st.cache_data(ttl=3600)\n",
        "def load_reference_data(_client):\n",
        "    if not _client: return {}, [], [], {}, [], {}\n",
        "    try:\n",
        "        df_paises = client.query(f\"SELECT country_name, country_id FROM `{PROJECT_ID}.{DATASET_ID}.Paises`\").to_dataframe()\n",
        "        country_options = [''] + sorted(df_paises['country_name'].unique().tolist())\n",
        "        cities_by_country = {country: [''] + sorted(df_paises[df_paises['country_name'] == country]['country_id'].tolist()) for country in df_paises['country_name'].unique()}\n",
        "        df_em = client.query(f\"SELECT Categoria, `Sub- categoria` FROM `{PROJECT_ID}.{DATASET_ID}.Examen_mental`\").to_dataframe()\n",
        "        df_em.columns = ['Categoria', 'Sub_categoria']\n",
        "        msea_data = {cat: sorted(group['Sub_categoria'].tolist()) for cat, group in df_em.groupby('Categoria')}\n",
        "        msea_order = ['Aspecto','Vestimenta','Biotipo','Actitud','Nivel de conciencia','Estado de conciencia','Orientación','Atención','Memoria','Lenguaje','Afectividad','Inteligencia','Velocidad del pensamiento','Curso del pensamiento','Tipo del pensamiento','Contenido de pensamiento','Sensopercepción','Juicio de realidad','Psicomotricidad','Conciencia de enfermedad']\n",
        "        df_diag = client.query(f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.Diagnostico`\").to_dataframe()\n",
        "        diag_categories = sorted(list(set(df_diag['Categoría'].dropna())))\n",
        "        grouped_diag_data = df_diag.groupby(['Categoría', 'Subcategoría']).apply(lambda x: x.to_dict('records')).to_dict()\n",
        "        return msea_data, msea_order, diag_categories, grouped_diag_data, country_options, cities_by_country\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al cargar datos de referencia: {e}\"); return {}, [], [], {}, [], {}\n",
        "\n",
        "# --- NAVEGACIÓN LATERAL ---\n",
        "with st.sidebar:\n",
        "    st.markdown(\"<div class='sidebar-title'>Áreas</div>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"---\")\n",
        "    if st.button(\"👤 Mi Consultorio\", use_container_width=True, type=\"primary\" if st.session_state.page == 'consultorio' else \"secondary\"):\n",
        "        st.session_state.page = 'consultorio'\n",
        "        st.session_state.current_patient_id = None\n",
        "        st.session_state.loaded_patient_id = None\n",
        "        st.rerun()\n",
        "    if st.button(\"🗓️ Agenda\", use_container_width=True, type=\"primary\" if st.session_state.page == 'agenda' else \"secondary\"):\n",
        "        st.session_state.page = 'agenda'; st.rerun()\n",
        "    if st.button(\"📊 Resumen Administrativo\", use_container_width=True, type=\"primary\" if st.session_state.page == 'resumen' else \"secondary\"):\n",
        "        st.session_state.page = 'resumen'; st.rerun()\n",
        "\n",
        "# --- RENDERIZADO DE PÁGINAS ---\n",
        "if not st.session_state.welcome_seen:\n",
        "    st.title(\"Bienvenido a MiEspacioTerapeutico\")\n",
        "    st.subheader(\"Tu centro de gestión clínica digital.\")\n",
        "    st.markdown(\"---\")\n",
        "    st.info(\"Organiza la información de tus pacientes, gestiona tus sesiones y lleva un control administrativo de tu consulta de forma sencilla y segura.\")\n",
        "    if st.button(\"Empezar a Gestionar\", type=\"primary\"):\n",
        "        st.session_state.welcome_seen = True; st.rerun()\n",
        "\n",
        "elif st.session_state.page == 'consultorio':\n",
        "    st.markdown('<h1 class=\"page-title\">Mi Consultorio</h1>', unsafe_allow_html=True)\n",
        "\n",
        "    @st.cache_data(ttl=60)\n",
        "    def get_all_patients_with_status(_client):\n",
        "        if not _client: return []\n",
        "        query = f\"\"\"SELECT p.id_paciente, p.nombre_completo, d.estado_paciente FROM `{PROJECT_ID}.{DATASET_ID}.pacientes` AS p LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.datos_administrativos` AS d ON p.id_paciente = d.id_paciente ORDER BY p.nombre_completo\"\"\"\n",
        "        try: return _client.query(query).to_dataframe().to_dict('records')\n",
        "        except: return []\n",
        "\n",
        "    patients = get_all_patients_with_status(client)\n",
        "\n",
        "    col1, col2 = st.columns([2, 1], vertical_alignment=\"bottom\")\n",
        "    with col1:\n",
        "        st.subheader(\"Buscar Paciente\")\n",
        "        search_query = st.text_input(\"Buscar Paciente\", placeholder=\"Escribe un nombre para buscar...\", label_visibility=\"collapsed\")\n",
        "    with col2:\n",
        "        if st.button(\"✚ Crear Nuevo Paciente\", type=\"primary\", use_container_width=True):\n",
        "            @st.dialog(\"Crear Nuevo Paciente\")\n",
        "            def create_patient_dialog():\n",
        "                with st.form(\"form_create_patient_dialog\"):\n",
        "                    name = st.text_input(\"Nombre y Apellido del Paciente\")\n",
        "                    if st.form_submit_button(\"Crear y Abrir Ficha\", type=\"primary\"):\n",
        "                        if name and name.strip():\n",
        "                            patient_id = generate_unique_id()\n",
        "                            if upsert_data('pacientes', {\"id_paciente\": patient_id, \"nombre_completo\": name}):\n",
        "                                st.success(f\"Paciente '{name}' creado.\"); on_select_patient(patient_id)\n",
        "                            else: st.error(\"No se pudo crear el paciente.\")\n",
        "            create_patient_dialog()\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    filtered_patients = patients\n",
        "    if search_query:\n",
        "        filtered_patients = [p for p in patients if search_query.lower() in p.get('nombre_completo', '').lower()]\n",
        "\n",
        "    active_patients = [p for p in filtered_patients if p.get('estado_paciente') == 'Activo']\n",
        "    inactive_patients = [p for p in filtered_patients if p.get('estado_paciente') != 'Activo']\n",
        "\n",
        "    st.subheader(\"Mis Pacientes\")\n",
        "    tab_todos, tab_activos, tab_inactivos = st.tabs([\n",
        "        f\"👥 Todos ({len(filtered_patients)})\",\n",
        "        f\"✅ Activos ({len(active_patients)})\",\n",
        "        f\"🚫 Inactivos ({len(inactive_patients)})\"\n",
        "    ])\n",
        "\n",
        "    def display_patient_list(patient_list, key_prefix):\n",
        "        if not patient_list:\n",
        "            st.info(\"No se encontraron pacientes que coincidan con los filtros seleccionados.\")\n",
        "            return\n",
        "\n",
        "        @st.dialog(\"Confirmar Eliminación\")\n",
        "        def delete_patient_dialog(patient_id, patient_name):\n",
        "            st.warning(f\"¿Estás seguro de que quieres eliminar a **{patient_name}**?\")\n",
        "            st.markdown(\"Esta acción es **irreversible** y borrará toda la historia clínica, sesiones y datos administrativos asociados.\")\n",
        "            c1, c2 = st.columns(2)\n",
        "            if c1.button(\"Cancelar\", use_container_width=True): st.rerun()\n",
        "            if c2.button(\"Eliminar Permanentemente\", type=\"primary\", use_container_width=True):\n",
        "                if delete_patient(patient_id):\n",
        "                    st.session_state.page = 'consultorio'\n",
        "                    st.session_state.current_patient_id = None\n",
        "                    st.rerun()\n",
        "\n",
        "        header_cols = st.columns([4, 2, 1, 1])\n",
        "        header_cols[0].markdown('<p class=\"column-header\">Nombre Completo</p>', unsafe_allow_html=True)\n",
        "        header_cols[1].markdown('<p class=\"column-header\">Estado</p>', unsafe_allow_html=True)\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "        for patient in patient_list:\n",
        "            data_cols = st.columns([4, 2, 1, 1], vertical_alignment=\"center\")\n",
        "            data_cols[0].markdown(f\"**{patient['nombre_completo']}**\")\n",
        "\n",
        "            status = patient.get('estado_paciente') or 'Indefinido'\n",
        "            color = \"green\" if status == \"Activo\" else \"orange\"\n",
        "            data_cols[1].markdown(f\"Estado: :{color}[{status}]\")\n",
        "\n",
        "            with data_cols[2]:\n",
        "                st.button(\"Abrir Ficha\", key=f\"{key_prefix}_view_{patient['id_paciente']}\", on_click=on_select_patient, args=(patient['id_paciente'],), use_container_width=True)\n",
        "            with data_cols[3]:\n",
        "                if st.button(\"Eliminar\", key=f\"{key_prefix}_del_{patient['id_paciente']}\", type=\"secondary\", use_container_width=True):\n",
        "                    delete_patient_dialog(patient['id_paciente'], patient['nombre_completo'])\n",
        "            st.divider()\n",
        "\n",
        "    with tab_todos:\n",
        "        display_patient_list(filtered_patients, key_prefix=\"all\")\n",
        "    with tab_activos:\n",
        "        display_patient_list(active_patients, key_prefix=\"active\")\n",
        "    with tab_inactivos:\n",
        "        display_patient_list(inactive_patients, key_prefix=\"inactive\")\n",
        "\n",
        "elif st.session_state.page == 'ficha' and st.session_state.current_patient_id:\n",
        "    if st.session_state.current_patient_id != st.session_state.get('loaded_patient_id'):\n",
        "        load_data_for_current_patient()\n",
        "\n",
        "    patient_id = st.session_state.current_patient_id\n",
        "    patient_name = st.session_state.get('pacientes', {}).get('nombre_completo', '')\n",
        "\n",
        "    st.markdown(f'<p class=\"patient-name-header\">{patient_name}</p>', unsafe_allow_html=True)\n",
        "    st.divider()\n",
        "\n",
        "    tab1, tab2, tab_sesiones, tab5, tab3, tab4 = st.tabs([\n",
        "        \"📝 Ficha Clínica\", \"🗂️ Datos Administrativos\", \"🗣️ Sesiones\",\n",
        "        \"🗓️ Agenda del Paciente\", \"🧠 Comprensión Psicodinámica\", \"📄 Resumen\"\n",
        "    ])\n",
        "\n",
        "    with tab1:\n",
        "        min_date_allowed = datetime.date(1940, 1, 1)\n",
        "        msea_data, msea_order, diag_categories, grouped_diag_data, country_options, cities_by_country = load_reference_data(client)\n",
        "        with st.expander(\"1. Datos de Identificación\", expanded=True):\n",
        "            data = st.session_state.get('datos_identificacion', {})\n",
        "            c1, c2 = st.columns(2)\n",
        "            with c1:\n",
        "                st.text_input(\"Nombre Completo\", value=patient_name, disabled=True, key=f\"di_name_{patient_id}\")\n",
        "                g_opts=['', 'Masculino', 'Femenino']; st.selectbox(\"Género\", g_opts, key=\"di_genero\", index=g_opts.index(data.get('genero')) if data.get('genero') in g_opts else 0)\n",
        "                pais_nacimiento = st.selectbox(\"País de Nacimiento\", country_options, key=\"di_pais_nacimiento\", index=country_options.index(data.get('pais_nacimiento')) if data.get('pais_nacimiento') in country_options else 0)\n",
        "                ciudades_nacimiento = cities_by_country.get(pais_nacimiento, [''])\n",
        "                st.selectbox(\"Ciudad de Nacimiento\", ciudades_nacimiento, key=\"di_ciudad_nacimiento\", index=ciudades_nacimiento.index(data.get('ciudad_nacimiento')) if data.get('ciudad_nacimiento') in ciudades_nacimiento else 0)\n",
        "                c_opts = ['','Soltero/a', 'Casado/a', 'Divorciado/a', 'Viudo/a', 'Unión libre']; st.selectbox(\"Estado Civil\", c_opts, key=\"di_estado_civil\", index=c_opts.index(data.get('estado_civil')) if data.get('estado_civil') in c_opts else 0)\n",
        "                if st.session_state.get('di_estado_civil') not in ['', 'Soltero/a']:\n",
        "                    st.date_input(\"Desde cuándo (Estado Civil)\", key=\"di_desde_cuando_estado_civil\", value=safe_date_converter(data.get('desde_cuando_estado_civil')), min_value=min_date_allowed)\n",
        "                l_opts = ['', 'Empleado', 'Desempleado', 'Estudiante', 'Jubilado', 'Nunca ha trabajado']; st.selectbox(\"Estado Laboral\", l_opts, key=\"di_estado_laboral\", index=l_opts.index(data.get('estado_laboral')) if data.get('estado_laboral') in l_opts else 0)\n",
        "                if st.session_state.get('di_estado_laboral') in ['Empleado', 'Desempleado', 'Estudiante']:\n",
        "                    st.text_input(\"Ocupación/Posición\", key=\"di_posicion_ocupacion\", value=data.get('posicion_ocupacion', ''))\n",
        "                    st.date_input(\"Desde cuándo (Laboral)\", key=\"di_desde_cuando_laboral\", value=safe_date_converter(data.get('desde_cuando_laboral')), min_value=min_date_allowed)\n",
        "            with c2:\n",
        "                st.number_input(\"Edad\", min_value=0, step=1, key=\"di_edad\", value=int(data.get('edad', 0)))\n",
        "                r_opts = ['', 'Catolicismo', 'Cristianismo (Otras ramas)', 'Judaísmo', 'Islam', 'Budismo', 'Hinduismo', 'Agnóstico', 'Ateo', 'Otra']; st.selectbox(\"Religión\", r_opts, key=\"di_religion\", index=r_opts.index(data.get('religion')) if data.get('religion') in r_opts else 0)\n",
        "                if st.session_state.get('di_religion') not in ['', 'Agnóstico', 'Ateo']:\n",
        "                    p_opts = ['', 'Practicante', 'No practicante', 'Ocasional']; st.selectbox(\"Nivel de práctica religiosa\", p_opts, key=\"di_nivel_de_practica_religiosa\", index=p_opts.index(data.get('nivel_de_practica_religiosa')) if data.get('nivel_de_practica_religiosa') in p_opts else 0)\n",
        "                pais_procedencia = st.selectbox(\"País de Procedencia\", country_options, key=\"di_pais_procedencia\", index=country_options.index(data.get('pais_procedencia')) if data.get('pais_procedencia') in country_options else 0)\n",
        "                ciudades_procedencia = cities_by_country.get(pais_procedencia, [''])\n",
        "                st.selectbox(\"Ciudad de Procedencia\", ciudades_procedencia, key=\"di_ciudad_procedencia\", index=ciudades_procedencia.index(data.get('ciudad_procedencia')) if data.get('ciudad_procedencia') in ciudades_procedencia else 0)\n",
        "                if st.session_state.get('di_pais_procedencia') != st.session_state.get('di_pais_nacimiento') or st.session_state.get('di_ciudad_procedencia') != st.session_state.get('di_ciudad_nacimiento'):\n",
        "                    st.date_input(\"Desde cuándo (Procedencia)\", key=\"di_desde_cuando_procedencia\", value=safe_date_converter(data.get('desde_cuando_procedencia')), min_value=min_date_allowed)\n",
        "                e_opts = ['', 'Sin estudios', 'Primaria', 'Secundaria', 'Universitaria', 'Máster', 'Doctorado']; st.selectbox(\"Nivel Educativo\", e_opts, key=\"di_nivel_educativo\", index=e_opts.index(data.get('nivel_educativo')) if data.get('nivel_educativo') in e_opts else 0)\n",
        "                if st.session_state.get('di_nivel_educativo') in ['Universitaria', 'Máster', 'Doctorado']:\n",
        "                    st.text_input(\"Área de estudio\", key=\"di_area_de_estudio\", value=data.get('area_de_estudio', ''))\n",
        "                st.number_input(\"Número de Parejas Anteriores\", min_value=0, step=1, key=\"di_numero_de_parejas_anteriores\", value=int(data.get('numero_de_parejas_anteriores', 0)))\n",
        "            st.markdown(\"---\")\n",
        "            tiene_hijos_actual = \"Sí\" if st.session_state.hijos_list else \"No\"\n",
        "            if st.radio(\"¿Tiene hijos?\", [\"No\", \"Sí\"], key=\"di_tiene_hijos\", horizontal=True, index=[\"No\", \"Sí\"].index(tiene_hijos_actual)) == \"Sí\":\n",
        "                with st.form(\"form_add_hijo\", clear_on_submit=True):\n",
        "                    c1,c2,c3 = st.columns([2,1,1])\n",
        "                    nombre_hijo = c1.text_input(\"Nombre del Hijo/a\")\n",
        "                    edad_hijo = c2.number_input(\"Edad\", min_value=0, step=1)\n",
        "                    if c3.form_submit_button(\"Añadir\"):\n",
        "                        if nombre_hijo: st.session_state.hijos_list.append({\"nombre\": nombre_hijo, \"edad\": int(edad_hijo)}); st.rerun()\n",
        "                if st.session_state.hijos_list:\n",
        "                    st.write(\"**Hijos Registrados:**\")\n",
        "                    for i, hijo in enumerate(list(st.session_state.hijos_list)):\n",
        "                        c1, c2 = st.columns([4, 1]); c1.markdown(f\"- {hijo['nombre']} ({hijo['edad']} años)\")\n",
        "                        if c2.button(\"X\", key=f\"del_hijo_{i}\"): st.session_state.hijos_list.pop(i); st.rerun()\n",
        "            elif st.session_state.hijos_list: st.session_state.hijos_list = []; st.rerun()\n",
        "            if st.button(\"💾 Guardar Datos de Identificación\", key=\"save_identificacion\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    ident_data = {'id_paciente': patient_id, 'nombre_completo': patient_name, 'edad': st.session_state.di_edad, 'genero': st.session_state.di_genero, 'pais_nacimiento': st.session_state.di_pais_nacimiento, 'ciudad_nacimiento': st.session_state.di_ciudad_nacimiento, 'estado_civil': st.session_state.di_estado_civil, 'desde_cuando_estado_civil': safe_date_converter(st.session_state.get('di_desde_cuando_estado_civil')), 'estado_laboral': st.session_state.di_estado_laboral, 'posicion_ocupacion': st.session_state.get('di_posicion_ocupacion'), 'desde_cuando_laboral': safe_date_converter(st.session_state.get('di_desde_cuando_laboral')), 'religion': st.session_state.di_religion, 'nivel_de_practica_religiosa': st.session_state.get('di_nivel_de_practica_religiosa'), 'pais_procedencia': st.session_state.di_pais_procedencia, 'ciudad_procedencia': st.session_state.di_ciudad_procedencia, 'desde_cuando_procedencia': safe_date_converter(st.session_state.get('di_desde_cuando_procedencia')), 'nivel_educativo': st.session_state.di_nivel_educativo, 'area_de_estudio': st.session_state.get('di_area_de_estudio'), 'numero_de_parejas_anteriores': st.session_state.di_numero_de_parejas_anteriores, 'hijos': st.session_state.hijos_list}\n",
        "                    if upsert_data('datos_identificacion', ident_data):\n",
        "                        st.success(\"✅ Datos de identificación guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "\n",
        "                        # ======================= MOTIVO + ENFERMEDAD ACTUAL =======================\n",
        "\n",
        "        with st.expander(\"2. Motivo de Consulta y Enfermedad Actual\", expanded=True):\n",
        "\n",
        "            # --- Motivo de consulta ---\n",
        "            st.write(\"Motivo de Consulta\")\n",
        "            motivo_content = st_quill(\n",
        "                value=st.session_state.get('motivo_de_consulta', {}).get('motivo_de_consulta', ''),\n",
        "                key=\"mc_motivo_quill\"\n",
        "            )\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # --- Enfermedad Actual (con asistente) ---\n",
        "            st.write(\"Enfermedad Actual\")\n",
        "\n",
        "            # Buffer local para el editor (como en Examen Mental con narrativa_temp)\n",
        "            if \"ea_temp\" not in st.session_state:\n",
        "                st.session_state.ea_temp = st.session_state.get('enfermedad_actual', {}).get('enfermedad_actual', '')\n",
        "\n",
        "            # Botón para abrir el asistente (modal)\n",
        "            if st.button(\"✍️ Asistente de Redacción de Enfermedad Actual\", use_container_width=True):\n",
        "                # Inicializamos/limpiamos estado del asistente\n",
        "                st.session_state.ea_asistente_citas = []\n",
        "                st.session_state.ea_narrativa_generada = \"\"\n",
        "                enfermedad_actual_assistant_dialog()\n",
        "\n",
        "            # Editor enriquecido con el buffer\n",
        "            enfermedad_content = st_quill(\n",
        "                value=st.session_state.ea_temp,\n",
        "                key=\"ea_enfermedad_quill\"\n",
        "            )\n",
        "\n",
        "            st.caption(\"Tip: puedes generar el texto con el asistente y luego ajustar manualmente aquí.\")\n",
        "\n",
        "            # Guardar en base de datos motivo + enfermedad actual\n",
        "            if st.button(\"💾 Guardar Motivo y Enfermedad\", key=\"save_motivo\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    # Actualizamos el buffer con lo que hay en el editor\n",
        "                    st.session_state.ea_temp = enfermedad_content\n",
        "\n",
        "                    flag1 = upsert_data('motivo_de_consulta', {\n",
        "                        'id_paciente': patient_id,\n",
        "                        'motivo_de_consulta': motivo_content\n",
        "                    })\n",
        "                    flag2 = upsert_data('enfermedad_actual', {\n",
        "                        'id_paciente': patient_id,\n",
        "                        'enfermedad_actual': st.session_state.ea_temp\n",
        "                    })\n",
        "                    if flag1 and flag2:\n",
        "                        st.success(\"✅ Motivo y Enfermedad Actual guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1)\n",
        "                        st.rerun()\n",
        "\n",
        "        # ======================= EXAMEN MENTAL (NUEVO) =======================\n",
        "        with st.expander(\"3. Examen Mental\"):\n",
        "            c1, c2 = st.columns(2)\n",
        "            c1.selectbox(\"Categoría\", [''] + msea_order, key=\"em_cat_sel\")\n",
        "            sub_opts = msea_data.get(st.session_state.em_cat_sel, [])\n",
        "            c2.selectbox(\"Subcategoría\", [''] + sub_opts, key=\"em_subcat_sel\", disabled=not st.session_state.em_cat_sel)\n",
        "\n",
        "            # --- Form para añadir ítems ---\n",
        "            with st.form(\"em_form\", clear_on_submit=True):\n",
        "                st.text_area(\"Notas Adicionales\", key=\"em_notas\")\n",
        "                add_disabled = not (st.session_state.em_cat_sel and st.session_state.em_subcat_sel)\n",
        "                if st.form_submit_button(\"Añadir Ítem\", disabled=add_disabled):\n",
        "                    st.session_state.selected_msea_items.append(\n",
        "                        {\n",
        "                            'categoria': st.session_state.em_cat_sel,\n",
        "                            'subcategoria': st.session_state.em_subcat_sel,\n",
        "                            'notas': st.session_state.em_notas\n",
        "                        }\n",
        "                    )\n",
        "                    st.rerun()\n",
        "\n",
        "            # --- Ítems Registrados en un expander (plegado para ahorrar espacio) ---\n",
        "            total_items = len(st.session_state.selected_msea_items or [])\n",
        "            with st.expander(f\"Ítems registrados ({total_items})\", expanded=False):\n",
        "                if st.session_state.selected_msea_items:\n",
        "                    for i, item in enumerate(list(st.session_state.selected_msea_items)):\n",
        "                        c1, c2 = st.columns([5, 1])\n",
        "                        c1.markdown(f\"- **{item['categoria']} / {item['subcategoria']}**: *{item.get('notas','')}*\")\n",
        "                        if c2.button(\"Eliminar\", key=f\"del_msea_{i}\"):\n",
        "                            st.session_state.selected_msea_items.pop(i)\n",
        "                            st.rerun()\n",
        "                else:\n",
        "                    st.caption(\"Aún no hay ítems registrados.\")\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Narrativa del Examen / Observaciones Generales:\")\n",
        "\n",
        "            # Estado inicial del editor\n",
        "            if \"narrativa_temp\" not in st.session_state:\n",
        "                st.session_state.narrativa_temp = st.session_state.get('examen_mental', {}).get('observaciones_generales', '')\n",
        "\n",
        "            # Estado para el modal de narrativa generada\n",
        "            if \"narrativa_generada\" not in st.session_state:\n",
        "                st.session_state.narrativa_generada = \"\"\n",
        "\n",
        "            # Editor enriquecido (para pegar manualmente si quieres)\n",
        "            obs_generales_content = st_quill(\n",
        "                value=st.session_state.narrativa_temp,\n",
        "                key=\"em_observaciones_generales_quill\"\n",
        "            )\n",
        "\n",
        "            # Modal de vista previa + copiar (sin \"Usar en Examen Mental\")\n",
        "            @st.dialog(\"Narrativa generada\", width=\"large\")\n",
        "            def show_narrativa_dialog():\n",
        "                texto = st.session_state.get(\"narrativa_generada\") or \"No se generó contenido.\"\n",
        "                st.markdown(\"**Vista previa (texto plano):**\")\n",
        "                st.text(texto)\n",
        "\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"**Copiar este contenido (usa el botón copiar arriba a la derecha):**\")\n",
        "                st.code(texto, language=\"markdown\")\n",
        "\n",
        "                if st.button(\"Cerrar\", use_container_width=True):\n",
        "                    st.rerun()\n",
        "\n",
        "            # Generar narrativa y abrir modal (usa SIEMPRE la V3 en texto plano)\n",
        "            def callback_generar_narrativa():\n",
        "                di = st.session_state.get('datos_identificacion', {})\n",
        "                genero = di.get('genero')\n",
        "                edad = di.get('edad')\n",
        "\n",
        "                texto = generar_narrativa_examen_v3(\n",
        "                    st.session_state.selected_msea_items,\n",
        "                    genero=genero,\n",
        "                    edad=edad\n",
        "                )\n",
        "\n",
        "                st.session_state.narrativa_generada = texto\n",
        "                show_narrativa_dialog()\n",
        "\n",
        "            st.button(\"✨ Generar Narrativa Automática\", key=\"gen_examen_mental\", on_click=callback_generar_narrativa)\n",
        "\n",
        "            # Guardar en base de datos lo que hay actualmente en el editor\n",
        "            if st.button(\"💾 Guardar Examen Mental\", key=\"save_examen_mental\", use_container_width=True):\n",
        "                st.session_state.narrativa_temp = obs_generales_content\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    examen_mental_data = {\n",
        "                        'id_paciente': patient_id,\n",
        "                        'msea_items': st.session_state.selected_msea_items,\n",
        "                        'observaciones_generales': obs_generales_content\n",
        "                    }\n",
        "                    if upsert_data('examen_mental', examen_mental_data):\n",
        "                        st.success(\"✅ Examen Mental guardado.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1)\n",
        "                        st.rerun()\n",
        "\n",
        "        # ==================== FIN EXAMEN MENTAL (NUEVO) ======================\n",
        "\n",
        "        with st.expander(\"4. Antecedentes Personales\"):\n",
        "            st.subheader(\"Antecedentes Médicos\")\n",
        "            with st.form(\"form_ap_medico\", clear_on_submit=True):\n",
        "                c1,c2=st.columns(2); cond=c1.text_input(\"Condición\"); desde=c2.date_input(\"Fecha Diag.\", value=None, min_value=min_date_allowed); notas=st.text_area(\"Notas\")\n",
        "                if st.form_submit_button(\"Añadir Ant. Médico\"):\n",
        "                    if cond: st.session_state.antecedentes_medicos_list.append({\"condicion\": cond, \"desde_cuando\": desde, \"notas\": notas}); st.rerun()\n",
        "            if st.session_state.antecedentes_medicos_list:\n",
        "                st.write(\"**Médicos Registrados:**\")\n",
        "                for i, ant in enumerate(list(st.session_state.antecedentes_medicos_list)):\n",
        "                    c1,c2=st.columns([4,1]); c1.markdown(f\"- **{ant.get('condicion','')}** ({ant.get('desde_cuando','N/A')}) - *{ant.get('notas','')}*\")\n",
        "                    if c2.button(\"X\", key=f\"del_am_{i}\"): st.session_state.antecedentes_medicos_list.pop(i); st.rerun()\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Antecedentes Psiquiátricos\")\n",
        "            with st.form(\"form_ap_psi\", clear_on_submit=True):\n",
        "                c1,c2=st.columns(2); trast=c1.text_input(\"Trastorno\"); desde_p=c2.date_input(\"Fecha Diag.\", value=None, min_value=min_date_allowed); notas_p=st.text_area(\"Notas\")\n",
        "                if st.form_submit_button(\"Añadir Ant. Psiquiátrico\"):\n",
        "                    if trast: st.session_state.antecedentes_psiquiatricos_list.append({\"trastorno\": trast, \"desde_cuando\": desde_p, \"notas\": notas_p}); st.rerun()\n",
        "            if st.session_state.antecedentes_psiquiatricos_list:\n",
        "                st.write(\"**Psiquiátricos Registrados:**\")\n",
        "                for i, ant in enumerate(list(st.session_state.antecedentes_psiquiatricos_list)):\n",
        "                    c1,c2=st.columns([4,1]); c1.markdown(f\"- **{ant.get('trastorno','')}** ({ant.get('desde_cuando','N/A')}) - *{ant.get('notas','')}*\")\n",
        "                    if c2.button(\"X\", key=f\"del_ap_{i}\"): st.session_state.antecedentes_psiquiatricos_list.pop(i); st.rerun()\n",
        "            if st.button(\"💾 Guardar Antecedentes Personales\", key=\"save_antecedentes_personales\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    antecedentes_personales_data = { 'id_paciente': patient_id, 'antecedentes_medicos': st.session_state.antecedentes_medicos_list, 'antecedentes_psiquiatricos': st.session_state.antecedentes_psiquiatricos_list }\n",
        "                    if upsert_data('antecedentes_personales', antecedentes_personales_data):\n",
        "                        st.success(\"✅ Antecedentes Personales guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "\n",
        "        with st.expander(\"5. Antecedentes Familiares\"):\n",
        "            with st.form(\"form_af\", clear_on_submit=True):\n",
        "                c1,c2,c3 = st.columns(3)\n",
        "                relacion = c1.selectbox(\"Relación\", ['', 'Padre', 'Madre', 'Hermano/a', 'Otro'], key=\"af_relacion\")\n",
        "                estado = c2.selectbox(\"Estado Vital\", ['Vivo', 'Fallecido'])\n",
        "                edad = c3.number_input(\"Edad\", min_value=0, step=1, value=0)\n",
        "                otra_relacion = st.text_input(\"Especifique otra relación\", key=\"af_otra_relacion\") if st.session_state.get('af_relacion') == 'Otro' else ''\n",
        "                condicion = st.text_input(\"Condición Médica Principal\", key=\"af_condicion\")\n",
        "                narrativa = st.text_area(\"Narrativa Psiquiátrica Familiar\", key=\"af_narrativa\")\n",
        "                if st.form_submit_button(\"Añadir Familiar\"):\n",
        "                    if relacion:\n",
        "                        condiciones = [{\"condicion\": condicion, \"otra_condicion\": \"\", \"notas\": \"\"}] if condicion else []\n",
        "                        st.session_state.familiares_list.append({ \"relacion\": relacion, \"otra_relacion\": otra_relacion, \"estado_vital\": estado, \"edad\": int(edad), \"condiciones_medicas\": condiciones, \"narrativa_psiquiatrica\": narrativa })\n",
        "                        st.rerun()\n",
        "            if st.session_state.familiares_list:\n",
        "                st.subheader(\"Familiares Registrados\")\n",
        "                for i, f in enumerate(list(st.session_state.familiares_list)):\n",
        "                    rel = f.get('otra_relacion') or f.get('relacion'); cond = \"N/A\"\n",
        "                    if f.get('condiciones_medicas') and f['condiciones_medicas']: cond = f['condiciones_medicas'][0].get('condicion', 'N/A')\n",
        "                    c1,c2 = st.columns([5,1]); c1.markdown(f\"- **{rel}** ({f.get('edad')} años, {f.get('estado_vital')}) - **Condición:** {cond}\")\n",
        "                    if c2.button(\"X\", key=f\"del_fam_{i}\"): st.session_state.familiares_list.pop(i); st.rerun()\n",
        "            if st.button(\"💾 Guardar Antecedentes Familiares\", key=\"save_antecedentes_familiares\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    antecedentes_familiares_data = { 'id_paciente': patient_id, 'familiares': st.session_state.familiares_list }\n",
        "                    if upsert_data('antecedentes_familiares', antecedentes_familiares_data):\n",
        "                        st.success(\"✅ Antecedentes Familiares guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "\n",
        "        with st.expander(\"6. Hábitos Psicobiológicos\"):\n",
        "            data = st.session_state.get('habitos_psicobiologicos', {})\n",
        "            sueno = data.get('sueno', {}); cafeina = data.get('cafeina', {}); alcohol = data.get('alcohol', {}); sustancias = data.get('sustancias_ilicitas', {})\n",
        "            st.checkbox(\"Presenta insomnio\", key=\"hp_sueno_insomnio\", value=sueno.get('insomnio', False))\n",
        "            if st.session_state.hp_sueno_insomnio:\n",
        "                s_opts = ['', 'Insomnio de conciliacion', 'Insomnio de mantenimiento', 'Insomnio mixto']; st.selectbox(\"Tipo de insomnio\", s_opts, key=\"hp_sueno_tipo_insomnio\", index=s_opts.index(sueno.get('tipo_insomnio')) if sueno.get('tipo_insomnio') in s_opts else 0)\n",
        "                c1,c2 = st.columns(2)\n",
        "                c1.number_input(\"Horas de sueño\", 0.0, 24.0, step=0.5, key=\"hp_sueno_horas\", value=float(sueno.get('horas', 0.0)))\n",
        "                c2.date_input(\"Insomnio desde\", key=\"hp_sueno_desde_cuando_insomnio\", value=safe_date_converter(sueno.get('desde_cuando_insomnio')), min_value=min_date_allowed)\n",
        "            st.divider()\n",
        "            st.checkbox(\"Consume cafeína\", key=\"hp_cafeina_consume\", value=cafeina.get('consume', False))\n",
        "            if st.session_state.hp_cafeina_consume:\n",
        "                c1,c2,c3=st.columns(3)\n",
        "                c1.text_input(\"Cantidad\", key=\"hp_cafeina_cantidad\", value=cafeina.get('cantidad',''))\n",
        "                c2.text_input(\"Frecuencia\", key=\"hp_cafeina_frecuencia\",value=cafeina.get('frecuencia',''))\n",
        "                c3.date_input(\"Consume desde\", key=\"hp_cafeina_desde_cuando\", value=safe_date_converter(cafeina.get('desde_cuando')), min_value=min_date_allowed)\n",
        "            st.divider()\n",
        "            st.checkbox(\"Consume alcohol\", key=\"hp_alcohol_consume\", value=alcohol.get('consume', False))\n",
        "            if st.session_state.hp_alcohol_consume:\n",
        "                c1,c2,c3=st.columns(3)\n",
        "                c1.text_input(\"Frecuencia\", key=\"hp_alcohol_frecuencia\", value=alcohol.get('frecuencia',''))\n",
        "                c2.text_input(\"Patrón\", key=\"hp_alcohol_patron\", value=alcohol.get('patron',''))\n",
        "                c3.date_input(\"Consume desde\", key=\"hp_alcohol_desde_cuando\", value=safe_date_converter(alcohol.get('desde_cuando')), min_value=min_date_allowed)\n",
        "            st.divider()\n",
        "            st.checkbox(\"Consume sustancias ilícitas\", key=\"hp_sustancias_consume\", value=sustancias.get('consume', False))\n",
        "            if st.session_state.hp_sustancias_consume:\n",
        "                c1,c2,c3=st.columns(3)\n",
        "                c1.text_input(\"Tipo\", key=\"hp_sustancias_tipo\", value=sustancias.get('tipo',''))\n",
        "                c2.text_input(\"Frecuencia\", key=\"hp_sustancias_frecuencia\",value=sustancias.get('frecuencia',''))\n",
        "                c3.date_input(\"Consume desde\", key=\"hp_sustancias_desde_cuando\", value=safe_date_converter(sustancias.get('desde_cuando')), min_value=min_date_allowed)\n",
        "            if st.button(\"💾 Guardar Hábitos Psicobiológicos\", key=\"save_habitos\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    habitos_data = {'id_paciente': patient_id, 'sueno': {'insomnio': st.session_state.hp_sueno_insomnio, 'tipo_insomnio': st.session_state.get('hp_sueno_tipo_insomnio'), 'horas': st.session_state.get('hp_sueno_horas'), 'desde_cuando_insomnio': safe_date_converter(st.session_state.get('hp_sueno_desde_cuando_insomnio'))}, 'cafeina': {'consume': st.session_state.hp_cafeina_consume, 'cantidad': st.session_state.get('hp_cafeina_cantidad'), 'frecuencia': st.session_state.get('hp_cafeina_frecuencia'), 'desde_cuando': safe_date_converter(st.session_state.get('hp_cafeina_desde_cuando'))}, 'alcohol': {'consume': st.session_state.hp_alcohol_consume, 'frecuencia': st.session_state.get('hp_alcohol_frecuencia'), 'patron': st.session_state.get('hp_alcohol_patron'), 'desde_cuando': safe_date_converter(st.session_state.get('hp_alcohol_desde_cuando'))}, 'sustancias_ilicitas': {'consume': st.session_state.hp_sustancias_consume, 'tipo': st.session_state.get('hp_sustancias_tipo'), 'frecuencia': st.session_state.get('hp_sustancias_frecuencia'), 'desde_cuando': safe_date_converter(st.session_state.get('hp_sustancias_desde_cuando'))}}\n",
        "                    if upsert_data('habitos_psicobiologicos', habitos_data):\n",
        "                        st.success(\"✅ Hábitos Psicobiológicos guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "\n",
        "        with st.expander(\"7. Diagnósticos\"):\n",
        "            c1,c2 = st.columns(2)\n",
        "            diag_cat = c1.selectbox(\"Categoría\", [''] + diag_categories, key=\"diag_cat_sel\")\n",
        "            subcat_opts = ['']\n",
        "            if diag_cat: subcat_opts.extend(sorted([k[1] for k in grouped_diag_data if k[0] == diag_cat]))\n",
        "            diag_subcat = c1.selectbox(\"Subcategoría\", subcat_opts, key=\"diag_subcat_sel\")\n",
        "            is_diag_selected = bool(diag_subcat)\n",
        "            spec_options, sev_options = [], ['']\n",
        "            if is_diag_selected:\n",
        "                details = grouped_diag_data.get((diag_cat, diag_subcat), [{}])[0]\n",
        "                spec_str = details.get('Especificadores', ''); sev_str = details.get('Nivel_Gravedad', '')\n",
        "                if spec_str: spec_options = [s.strip() for s in spec_str.split(';') if s.strip()]\n",
        "                if sev_str: sev_options.extend([s.strip() for s in sev_str.split('/') if s.strip()])\n",
        "            c2.multiselect(\"Especificadores\", spec_options, key=\"diag_spec_sel\", disabled=not is_diag_selected)\n",
        "            c2.selectbox(\"Gravedad\", sev_options, key=\"diag_sev_sel\", disabled=not is_diag_selected)\n",
        "            if st.button(\"Añadir Diagnóstico\"):\n",
        "                if diag_cat and diag_subcat:\n",
        "                    st.session_state.current_patient_diagnoses.append({\"categoria\": diag_cat, \"subcategoria\": diag_subcat, \"especificadores\": st.session_state.diag_spec_sel, \"gravedad\": st.session_state.diag_sev_sel}); st.rerun()\n",
        "            if st.session_state.current_patient_diagnoses:\n",
        "                st.markdown(\"---\"); st.subheader(\"Diagnósticos Registrados\")\n",
        "                for i, diag in enumerate(list(st.session_state.current_patient_diagnoses)):\n",
        "                    c1,c2 = st.columns([5,1]); summary = f\"**{diag['subcategoria']}**\"; spec = \", \".join(diag.get('especificadores',[])); summary += f\" (*{spec}*)\" if spec else \"\"; summary += f\" - {diag.get('gravedad')}\" if diag.get('gravedad') else \"\"\n",
        "                    c1.markdown(f\"- {summary}\")\n",
        "                    if c2.button(\"X\", key=f\"del_diag_{i}\"): st.session_state.current_patient_diagnoses.pop(i); st.rerun()\n",
        "            if st.button(\"💾 Guardar Diagnósticos\", key=\"save_diagnosticos\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    diag_list = [{'categoria': d.get('categoria'), 'subcategoria': d.get('subcategoria'), 'especificadores': ', '.join(d.get('especificadores', [])) if isinstance(d.get('especificadores'), list) else d.get('especificadores'), 'gravedad': d.get('gravedad')} for d in st.session_state.current_patient_diagnoses]\n",
        "                    if upsert_data('diagnosticos', {'id_paciente': patient_id, 'diagnosticos': diag_list}):\n",
        "                        st.success(\"✅ Diagnósticos guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "\n",
        "        with st.expander(\"8. Tratamientos\"):\n",
        "            st.subheader(\"Tratamiento Farmacológico\")\n",
        "            with st.form(\"form_trat_farma\", clear_on_submit=True):\n",
        "                c1,c2,c3 = st.columns(3); farmaco = c1.text_input(\"Fármaco\"); dosis = c2.text_input(\"Dosis\"); via = c3.text_input(\"Vía\")\n",
        "                c4,c5 = st.columns(2); inicio = c4.date_input(\"Fecha Inicio\", value=None, min_value=min_date_allowed); actualizacion = c5.date_input(\"Última Actualización\", value=datetime.date.today(), min_value=min_date_allowed)\n",
        "                notas = st.text_area(\"Notas\")\n",
        "                if st.form_submit_button(\"Añadir Tto. Farmacológico\"):\n",
        "                    if farmaco: st.session_state.tratamientos_farmacologicos_list.append({'farmaco':farmaco, 'dosis':dosis, 'via':via, 'inicio':inicio, 'ultima_actualizacion':actualizacion, 'notas':notas}); st.rerun()\n",
        "            if st.session_state.tratamientos_farmacologicos_list: st.dataframe(pd.DataFrame(st.session_state.tratamientos_farmacologicos_list), use_container_width=True)\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Tratamiento Psiquiátrico\")\n",
        "            with st.form(\"form_trat_psi\", clear_on_submit=True):\n",
        "                c1,c2,c3 = st.columns(3); farmaco_p = c1.text_input(\"Fármaco\"); dosis_p = c2.text_input(\"Dosis\"); via_p = c3.text_input(\"Vía\")\n",
        "                c4,c5 = st.columns(2); inicio_p = c4.date_input(\"Fecha Inicio\", value=None, min_value=min_date_allowed); actualizacion_p = c5.date_input(\"Última Actualización\", value=datetime.date.today(), min_value=min_date_allowed)\n",
        "                notas_p = st.text_area(\"Notas\")\n",
        "                if st.form_submit_button(\"Añadir Tto. Psiquiátrico\"):\n",
        "                    if farmaco_p: st.session_state.tratamientos_psiquiatricos_list.append({'farmaco':farmaco_p, 'dosis':dosis_p, 'via':via_p, 'inicio':inicio_p, 'ultima_actualizacion':actualizacion_p, 'notas':notas_p}); st.rerun()\n",
        "            if st.session_state.tratamientos_psiquiatricos_list: st.dataframe(pd.DataFrame(st.session_state.tratamientos_psiquiatricos_list), use_container_width=True)\n",
        "            if st.button(\"💾 Guardar Tratamientos\", key=\"save_tratamientos\", use_container_width=True):\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    tratamientos_data = { 'id_paciente': patient_id, 'farmacologico': st.session_state.tratamientos_farmacologicos_list, 'psiquiatrico': st.session_state.tratamientos_psiquiatricos_list }\n",
        "                    if upsert_data('tratamientos', tratamientos_data):\n",
        "                        st.success(\"✅ Tratamientos guardados.\")\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "\n",
        "    with tab2:\n",
        "        data = st.session_state.get('datos_administrativos', {})\n",
        "        with st.form(\"admin_form\"):\n",
        "            c1, c2 = st.columns(2)\n",
        "            with c1:\n",
        "                st.text_input(\"Teléfono de Contacto\", data.get('telefono',''), key=\"admin_telefono\")\n",
        "                frec_opts=['','Semanal','Quincenal','Mensual','Variable']; st.selectbox(\"Frecuencia de Sesiones\", frec_opts, key=\"admin_frecuencia\", index=frec_opts.index(data.get('frecuencia')) if data.get('frecuencia') in frec_opts else 0)\n",
        "                st.time_input(\"Hora de Sesión Habitual\", safe_time_converter(data.get('hora_sesion')), key=\"admin_hora_sesion\")\n",
        "                st.number_input(\"Honorarios (€)\", min_value=0.0, step=5.0, value=float(data.get('Honorarios', 0.0)), key=\"admin_honorarios\")\n",
        "            with c2:\n",
        "                st.text_input(\"Correo Electrónico\", data.get('email',''), key=\"admin_email\")\n",
        "                dias_opts=['','Lunes','Martes','Miércoles','Jueves','Viernes','Sábado','Domingo']; st.selectbox(\"Día de Sesión Habitual\", dias_opts, key=\"admin_dia_sesion\", index=dias_opts.index(data.get('dia_sesion')) if data.get('dia_sesion') in dias_opts else 0)\n",
        "                est_opts=['Activo','Inactivo']; st.selectbox(\"Estado del Paciente\", est_opts, key=\"admin_estado_paciente\", index=est_opts.index(data.get('estado_paciente')) if data.get('estado_paciente') in est_opts else 0)\n",
        "                st.date_input(\"Próxima Fecha de Pago\", safe_date_converter(data.get('Fecha de pago')), key=\"admin_fecha_pago\")\n",
        "\n",
        "            if st.form_submit_button(\"💾 Guardar Datos Administrativos\", use_container_width=True, type=\"primary\"):\n",
        "                admin_data_to_save = {\n",
        "                    'id_paciente': patient_id, 'telefono': st.session_state.admin_telefono, 'email': st.session_state.admin_email,\n",
        "                    'frecuencia': st.session_state.admin_frecuencia, 'dia_sesion': st.session_state.admin_dia_sesion,\n",
        "                    'hora_sesion': st.session_state.admin_hora_sesion,\n",
        "                    'estado_paciente': st.session_state.admin_estado_paciente,\n",
        "                    'Honorarios': safe_decimal_converter(st.session_state.admin_honorarios),\n",
        "                    'Fecha de pago': safe_date_converter(st.session_state.admin_fecha_pago)\n",
        "                }\n",
        "                with st.spinner(\"Guardando...\"):\n",
        "                    if upsert_data('datos_administrativos', admin_data_to_save):\n",
        "                        st.success(\"✅ Datos administrativos guardados.\");\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        time.sleep(1); st.rerun()\n",
        "                    else: st.error(\"❌ Error al guardar datos administrativos.\")\n",
        "\n",
        "    with tab_sesiones:\n",
        "        with st.form(\"form_add_sesion\", clear_on_submit=True):\n",
        "            st.write(\"**Añadir Nueva Sesión**\")\n",
        "            fecha_sesion = st.date_input(\"Fecha de Sesión\", value=datetime.date.today())\n",
        "            transcripcion_content = st_quill(key=\"sesion_transcripcion_quill\")\n",
        "            if st.form_submit_button(\"Añadir Sesión\"):\n",
        "                if fecha_sesion and transcripcion_content:\n",
        "                    sesion_data = {'id_sesion': generate_unique_id(), 'id_paciente': patient_id, 'fecha_de_sesion': fecha_sesion, 'transcripcion': transcripcion_content}\n",
        "                    if upsert_data('sesiones', sesion_data):\n",
        "                        st.success(\"✅ Sesión añadida.\"); st.session_state.sesiones_list.append(sesion_data)\n",
        "                        st.cache_data.clear()\n",
        "                        st.session_state.loaded_patient_id = None\n",
        "                        st.rerun()\n",
        "        st.divider()\n",
        "        if st.session_state.sesiones_list:\n",
        "            st.write(\"**Sesiones Registradas**\")\n",
        "            @st.dialog(\"Confirmar Eliminación de Sesión\")\n",
        "            def delete_session_dialog(session_id, session_date):\n",
        "                st.warning(f\"¿Seguro que quieres eliminar la sesión del **{session_date}**?\")\n",
        "                c1, c2 = st.columns(2)\n",
        "                if c1.button(\"Cancelar\", use_container_width=True): st.rerun()\n",
        "                if c2.button(\"Eliminar\", type=\"primary\", use_container_width=True):\n",
        "                    if delete_record('sesiones', session_id, 'id_sesion'):\n",
        "                        st.session_state.sesiones_list = [s for s in st.session_state.sesiones_list if s.get('id_sesion') != session_id]\n",
        "                        st.cache_data.clear()\n",
        "                        st.rerun()\n",
        "\n",
        "            for sesion in sorted(st.session_state.sesiones_list, key=lambda x: (safe_date_converter(x.get('fecha_de_sesion')) or datetime.date.min), reverse=True):\n",
        "                with st.expander(f\"**Sesión del {sesion.get('fecha_de_sesion')}**\"):\n",
        "                    st.markdown(sesion.get('transcripcion', ''), unsafe_allow_html=True)\n",
        "                    if st.button(\"Eliminar Sesión\", key=f\"del_sesion_{sesion.get('id_sesion')}\", type=\"secondary\"):\n",
        "                        delete_session_dialog(sesion.get('id_sesion'), sesion.get('fecha_de_sesion'))\n",
        "        else: st.info(\"No hay sesiones registradas.\")\n",
        "\n",
        "    with tab5:\n",
        "        with st.form(\"form_add_cita\", clear_on_submit=True):\n",
        "            st.write(\"**Añadir Nueva Cita**\")\n",
        "            c1, c2 = st.columns(2)\n",
        "            default_datetime = datetime.datetime.now()\n",
        "            fecha_cita = c1.date_input(\"Fecha de Cita\", value=default_datetime.date())\n",
        "            hora_cita = c2.time_input(\"Hora de Cita\", value=default_datetime.time())\n",
        "            est_cita_opts = ['Pendiente','Confirmada','Cancelada','Realizada']\n",
        "            estado_cita = st.selectbox(\"Estado de la Cita\", est_cita_opts, key=\"cita_estado\")\n",
        "            if st.form_submit_button(\"Añadir Cita\"):\n",
        "                cita_data = {'id_cita': generate_unique_id(), 'id_paciente': patient_id, 'fecha_de_cita': fecha_cita, 'hora': hora_cita, 'estado_de_la_cita': estado_cita}\n",
        "                if upsert_data('agenda', cita_data):\n",
        "                    st.success(\"✅ Cita añadida.\"); st.session_state.agenda_list.append(cita_data)\n",
        "                    st.cache_data.clear()\n",
        "                    st.rerun()\n",
        "        st.divider()\n",
        "        st.write(\"**Citas Registradas**\")\n",
        "        if st.session_state.agenda_list:\n",
        "            @st.dialog(\"Confirmar Eliminación de Cita\")\n",
        "            def delete_appointment_dialog(cita_id, cita_date, cita_time):\n",
        "                st.warning(f\"¿Seguro que quieres eliminar la cita del **{cita_date}** a las **{cita_time}**?\")\n",
        "                c1, c2 = st.columns(2)\n",
        "                if c1.button(\"Cancelar\", use_container_width=True): st.rerun()\n",
        "                if c2.button(\"Eliminar\", type=\"primary\", use_container_width=True):\n",
        "                    if delete_record('agenda', cita_id, 'id_cita'):\n",
        "                        st.session_state.agenda_list = [c for c in st.session_state.agenda_list if c.get('id_cita') != cita_id]\n",
        "                        st.cache_data.clear()\n",
        "                        st.rerun()\n",
        "\n",
        "            for cita in sorted(st.session_state.agenda_list, key=lambda x: (safe_date_converter(x.get('fecha_de_cita')) or datetime.date.min, safe_time_converter(x.get('hora')) or datetime.time.min)):\n",
        "                col1, col2 = st.columns([4, 1])\n",
        "                col1.markdown(f\"- **{safe_date_converter(cita.get('fecha_de_cita'))}** a las {safe_time_converter(cita.get('hora'))} - Estado: **{cita.get('estado_de_la_cita')}**\")\n",
        "                if col2.button(\"Eliminar\", key=f\"del_cita_{cita.get('id_cita')}\"):\n",
        "                    delete_appointment_dialog(cita.get('id_cita'), cita.get('fecha_de_cita'), cita.get('hora'))\n",
        "        else: st.info(\"No hay citas registradas para este paciente.\")\n",
        "\n",
        "    with tab3:\n",
        "        data = st.session_state.get('comprension_psicodinamica', {})\n",
        "        st.write(\"**Comprensión Psicodinámica**\")\n",
        "        comprension_content = st_quill(value=data.get('comprension', ''), key=\"comprension_quill\")\n",
        "        if st.button(\"💾 Guardar Comprensión\", use_container_width=True, type=\"primary\"):\n",
        "            if upsert_data('comprension_psicodinamica', {'id_paciente': patient_id, 'comprension': comprension_content}):\n",
        "                st.success(\"✅ Comprensión guardada.\")\n",
        "                st.cache_data.clear()\n",
        "                st.session_state.loaded_patient_id = None\n",
        "                time.sleep(1); st.rerun()\n",
        "            else: st.error(\"❌ Error al guardar la comprensión.\")\n",
        "\n",
        "    with tab4:\n",
        "        @st.dialog(\"Resumen de Historia Clínica\", width=\"large\")\n",
        "        def show_summary_dialog():\n",
        "            st.header(f\"Informe de: {patient_name}\")\n",
        "            st.caption(f\"Generado el: {datetime.date.today().strftime('%d/%m/%Y')}\")\n",
        "            st.divider()\n",
        "\n",
        "            st.subheader(\"1. Datos de Identificación\")\n",
        "            id_data = st.session_state.get('datos_identificacion', {})\n",
        "            admin_data = st.session_state.get('datos_administrativos', {})\n",
        "            col1, col2 = st.columns(2)\n",
        "            col1.markdown(f\"**Edad:** {id_data.get('edad', 'N/A')} años\")\n",
        "            col1.markdown(f\"**Género:** {id_data.get('genero', 'N/A')}\")\n",
        "            col1.markdown(f\"**Estado Civil:** {id_data.get('estado_civil', 'N/A')}\")\n",
        "            col1.markdown(f\"**Teléfono:** {admin_data.get('telefono', 'N/A')}\")\n",
        "            col2.markdown(f\"**Ocupación:** {id_data.get('posicion_ocupacion', 'N/A')} ({id_data.get('estado_laboral', 'N/A')})\")\n",
        "            col2.markdown(f\"**Nivel Educativo:** {id_data.get('nivel_educativo', 'N/A')}\")\n",
        "            col2.markdown(f\"**País de Procedencia:** {id_data.get('pais_procedencia', 'N/A')}\")\n",
        "            col2.markdown(f\"**Email:** {admin_data.get('email', 'N/A')}\")\n",
        "            if st.session_state.hijos_list:\n",
        "                nombres_hijos = \", \".join([f\"{h['nombre']} ({h['edad']} años)\" for h in st.session_state.hijos_list])\n",
        "                st.markdown(f\"**Hijos:** {nombres_hijos}\")\n",
        "\n",
        "            st.subheader(\"2. Motivo de Consulta y Enfermedad Actual\")\n",
        "            st.markdown(\"**Motivo:**\")\n",
        "            st.markdown(st.session_state.get('motivo_de_consulta',{}).get('motivo_de_consulta', 'No registrado.'), unsafe_allow_html=True)\n",
        "            with st.expander(\"Ver Enfermedad Actual\"):\n",
        "                st.markdown(st.session_state.get('enfermedad_actual',{}).get('enfermedad_actual', 'No registrada.'), unsafe_allow_html=True)\n",
        "\n",
        "            st.subheader(\"3. Antecedentes\")\n",
        "            with st.expander(\"Personales\"):\n",
        "                st.markdown(\"**Médicos:**\")\n",
        "                if st.session_state.antecedentes_medicos_list:\n",
        "                    for ant in st.session_state.antecedentes_medicos_list: st.markdown(f\"- {ant.get('condicion','')} ({ant.get('desde_cuando','N/A')})\")\n",
        "                else: st.caption(\"No registrados.\")\n",
        "                st.markdown(\"**Psiquiátricos:**\")\n",
        "                if st.session_state.antecedentes_psiquiatricos_list:\n",
        "                    for ant in st.session_state.antecedentes_psiquiatricos_list: st.markdown(f\"- {ant.get('trastorno','')} ({ant.get('desde_cuando','N/A')})\")\n",
        "                else: st.caption(\"No registrados.\")\n",
        "            with st.expander(\"Familiares\"):\n",
        "                 if st.session_state.familiares_list:\n",
        "                    for f in st.session_state.familiares_list:\n",
        "                        rel = f.get('otra_relacion') or f.get('relacion')\n",
        "                        cond = \"N/A\"\n",
        "                        if f.get('condiciones_medicas') and f['condiciones_medicas']: cond = f['condiciones_medicas'][0].get('condicion', 'N/A')\n",
        "                        st.markdown(f\"- **{rel}** ({f.get('estado_vital')}): {cond}\")\n",
        "                 else: st.caption(\"No registrados.\")\n",
        "\n",
        "            st.subheader(\"4. Examen Mental\")\n",
        "            examen_mental_data = st.session_state.get('examen_mental', {})\n",
        "            narrativa = examen_mental_data.get('observaciones_generales')\n",
        "            if narrativa:\n",
        "                st.markdown(narrativa, unsafe_allow_html=True)\n",
        "            else:\n",
        "                st.caption(\"No se registró información del examen mental.\")\n",
        "\n",
        "            st.subheader(\"5. Diagnósticos\")\n",
        "            if st.session_state.current_patient_diagnoses:\n",
        "                for diag in st.session_state.current_patient_diagnoses:\n",
        "                    spec = \", \".join(diag.get('especificadores', []))\n",
        "                    st.markdown(f\"- **{diag.get('subcategoria')}** {f'({spec})' if spec else ''} - *Gravedad: {diag.get('gravedad', 'N/A')}*\")\n",
        "            else: st.caption(\"No hay diagnósticos registrados.\")\n",
        "\n",
        "            st.subheader(\"6. Tratamiento Actual\")\n",
        "            if st.session_state.tratamientos_farmacologicos_list or st.session_state.tratamientos_psiquiatricos_list:\n",
        "                c1, c2 = st.columns(2)\n",
        "                with c1:\n",
        "                    st.markdown(\"**Farmacológico:**\")\n",
        "                    if st.session_state.tratamientos_farmacologicos_list:\n",
        "                        for t in st.session_state.tratamientos_farmacologicos_list: st.markdown(f\"- {t.get('farmaco')} {t.get('dosis')}\")\n",
        "                    else: st.caption(\"No registrado.\")\n",
        "                with c2:\n",
        "                    st.markdown(\"**Psiquiátrico:**\")\n",
        "                    if st.session_state.tratamientos_psiquiatricos_list:\n",
        "                        for t in st.session_state.tratamientos_psiquiatricos_list: st.markdown(f\"- {t.get('farmaco')} {t.get('dosis')}\")\n",
        "                    else: st.caption(\"No registrado.\")\n",
        "            else: st.caption(\"No hay tratamientos registrados.\")\n",
        "\n",
        "            st.divider()\n",
        "            if st.button(\"Cerrar\", key=\"close_summary\"): st.rerun()\n",
        "\n",
        "        st.info(\"Genera una vista consolidada y detallada de los datos más importantes del paciente.\")\n",
        "        if st.button(\"Ver Resumen de Historia Clínica\", use_container_width=True, type=\"primary\"):\n",
        "            show_summary_dialog()\n",
        "\n",
        "elif st.session_state.page == 'agenda':\n",
        "    st.markdown('<h1 class=\"page-title\">🗓️ Agenda General</h1>', unsafe_allow_html=True)\n",
        "    @st.cache_data(ttl=60)\n",
        "    def get_global_agenda(_client):\n",
        "        if not _client: return pd.DataFrame()\n",
        "        query = f\"\"\"SELECT p.nombre_completo, a.fecha_de_cita, a.hora, a.estado_de_la_cita FROM `{PROJECT_ID}.{DATASET_ID}.agenda` AS a LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.pacientes` AS p ON a.id_paciente = p.id_paciente WHERE a.fecha_de_cita >= CURRENT_DATE() ORDER BY a.fecha_de_cita, a.hora\"\"\"\n",
        "        try: return _client.query(query).to_dataframe()\n",
        "        except Exception as e: st.error(f\"Error al cargar agenda: {e}\"); return pd.DataFrame()\n",
        "    agenda_df = get_global_agenda(client)\n",
        "    if not agenda_df.empty: st.dataframe(agenda_df.rename(columns={'nombre_completo': 'Paciente', 'fecha_de_cita': 'Fecha', 'hora': 'Hora', 'estado_de_la_cita': 'Estado'}), use_container_width=True)\n",
        "    else: st.info(\"No hay citas próximas en la agenda.\")\n",
        "\n",
        "elif st.session_state.page == 'resumen':\n",
        "    st.markdown('<h1 class=\"page-title\">📊 Resumen Administrativo</h1>', unsafe_allow_html=True)\n",
        "    @st.cache_data(ttl=600)\n",
        "    def get_dashboard_kpis(_client):\n",
        "        if not _client: return {}\n",
        "        kpis = {}\n",
        "        try:\n",
        "            query_income = f\"\"\"SELECT SUM(IF(EXTRACT(YEAR FROM `Fecha de pago`) = EXTRACT(YEAR FROM CURRENT_DATE()) AND EXTRACT(MONTH FROM `Fecha de pago`) = EXTRACT(MONTH FROM CURRENT_DATE()), Honorarios, 0)) AS current_month_income FROM `{PROJECT_ID}.{DATASET_ID}.datos_administrativos`\"\"\"\n",
        "            df_income = _client.query(query_income).to_dataframe()\n",
        "            kpis['income'] = df_income['current_month_income'].iloc[0] if pd.notna(df_income['current_month_income'].iloc[0]) else 0\n",
        "\n",
        "            query_patients = f\"\"\"SELECT d.estado_paciente, i.genero, COUNT(p.id_paciente) as count FROM `{PROJECT_ID}.{DATASET_ID}.pacientes` p LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.datos_administrativos` d ON p.id_paciente = d.id_paciente LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.datos_identificacion` i ON p.id_paciente = i.id_paciente GROUP BY 1, 2\"\"\"\n",
        "            df_patients = _client.query(query_patients).to_dataframe()\n",
        "            kpis['total_patients'] = int(df_patients['count'].sum())\n",
        "            kpis['active_patients'] = int(df_patients[df_patients['estado_paciente'] == 'Activo']['count'].sum())\n",
        "            kpis['inactive_patients'] = kpis['total_patients'] - kpis['active_patients']\n",
        "            kpis['gender_dist'] = df_patients.groupby('genero')['count'].sum().to_dict()\n",
        "            return kpis\n",
        "        except Exception as e: st.warning(f\"No se pudo calcular KPIs: {e}\"); return {}\n",
        "\n",
        "    kpis = get_dashboard_kpis(client)\n",
        "    c1, c2, c3 = st.columns(3)\n",
        "    c1.metric(\"Ingresos del Mes\", f\"{kpis.get('income', 0):,.2f} €\")\n",
        "    c2.metric(\"Total Pacientes\", kpis.get('total_patients', 0))\n",
        "    c3.metric(\"Pacientes Activos\", f\"{kpis.get('active_patients',0)} (Inactivos: {kpis.get('inactive_patients', 0)})\")\n",
        "\n",
        "    gender_data = kpis.get('gender_dist', {})\n",
        "    if gender_data:\n",
        "        st.markdown(\"**Distribución por Género:**\")\n",
        "        clean_gender_data = {k: v for k, v in gender_data.items() if k}\n",
        "        if clean_gender_data:\n",
        "            df_gender = pd.DataFrame.from_dict(clean_gender_data, orient='index', columns=['Pacientes'])\n",
        "            st.bar_chart(df_gender)\n",
        "\n",
        "else:\n",
        "    st.session_state.page = 'consultorio'\n",
        "    st.rerun()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-xCy0bsWf_a",
        "outputId": "97bc7533-5f2c-467b-89f5-558e6b140f1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG5G-4uVK27e"
      },
      "source": [
        "#FASE DE EJECUCIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWJlM06otoGO"
      },
      "source": [
        "# Ejecución de la Aplicación Streamlit y del Túnel ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Coc9lesctsUW",
        "outputId": "ac0a21d7-008f-4e0e-9da6-3413d3cd7e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intentando detener procesos existentes en puerto 8501...\n",
            "✓ Procesos detenidos.\n",
            "--------------------------------------------------\n",
            "Iniciando aplicación Streamlit en segundo plano...\n",
            "✓ Aplicación Streamlit iniciada en segundo plano en el puerto 8501.\n",
            "--------------------------------------------------\n",
            "Iniciando túnel ngrok...\n",
            "\n",
            "🎉 ¡Éxito! Túnel ngrok establecido. URL pública:\n",
            "🔗 https://43b68039b057.ngrok-free.app\n",
            "\n",
            "👉 Haz clic en la URL de arriba para acceder a tu aplicación Streamlit.\n",
            "Nota: La aplicación se está ejecutando en segundo plano. Para detenerla, ejecuta la primera celda de este paso de nuevo.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# --- PASO 5: EJECUCIÓN DE STREAMLIT Y NGROK ---\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Detener cualquier proceso de Streamlit o ngrok que use el puerto 8501\n",
        "print(\"Intentando detener procesos existentes en puerto 8501...\")\n",
        "try:\n",
        "    !pkill -f \"streamlit run\"\n",
        "    ngrok.kill()\n",
        "    time.sleep(5)  # Esperar a que los procesos terminen\n",
        "    print(\"✓ Procesos detenidos.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ No se encontraron procesos para detener o ocurrió un error: {e}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Iniciar la aplicación Streamlit en segundo plano\n",
        "print(\"Iniciando aplicación Streamlit en segundo plano...\")\n",
        "!streamlit run app.py --server.port 8501 > streamlit_output.log 2>&1 &\n",
        "print(\"✓ Aplicación Streamlit iniciada en segundo plano en el puerto 8501.\")\n",
        "time.sleep(10) # Dar tiempo a que Streamlit inicie\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Iniciar el túnel ngrok y obtener la URL pública\n",
        "print(\"Iniciando túnel ngrok...\")\n",
        "try:\n",
        "    tunnel = ngrok.connect(8501)\n",
        "    public_url = tunnel.public_url\n",
        "    print(\"\\n🎉 ¡Éxito! Túnel ngrok establecido. URL pública:\")\n",
        "    print(f\"🔗 {public_url}\")\n",
        "    print(\"\\n👉 Haz clic en la URL de arriba para acceder a tu aplicación Streamlit.\")\n",
        "    print(\"Nota: La aplicación se está ejecutando en segundo plano. Para detenerla, ejecuta la primera celda de este paso de nuevo.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️ Ocurrió un error al iniciar el túnel ngrok: {e}\")\n",
        "    print(\"Por favor, verifica el token de ngrok y el contenido del log de Streamlit.\")\n",
        "    print(\"\\n--- Contenido reciente de streamlit_output.log ---\")\n",
        "    try:\n",
        "        with open('streamlit_output.log', 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            last_lines = lines[-20:] if len(lines) > 20 else lines\n",
        "            print(\"\".join(last_lines))\n",
        "    except FileNotFoundError:\n",
        "        print(\"El archivo streamlit_output.log aún no se ha creado o encontrado.\")\n",
        "    except Exception as read_e:\n",
        "        print(f\"Ocurrió un error al leer el archivo de log: {read_e}\")\n",
        "\n",
        "print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}